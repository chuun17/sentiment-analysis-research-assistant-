{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataset/Data 1.xlsx', names=['comment', 'polarity'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min bnyk yg kecewa lo dgn update terbaru alih ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user id password mesti ke bank ya gpplah yg pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saat transfer kadang ada muncul keterangan kon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>begitu saya update dan no tlpn saya statusnya ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tolong tambahkan fitur fingerprint atau face r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  polarity\n",
       "0  min bnyk yg kecewa lo dgn update terbaru alih ...         1\n",
       "1  user id password mesti ke bank ya gpplah yg pe...         1\n",
       "2  saat transfer kadang ada muncul keterangan kon...         1\n",
       "3  begitu saya update dan no tlpn saya statusnya ...         1\n",
       "4  tolong tambahkan fitur fingerprint atau face r...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<ol>\n",
    "    <li>Case folding <b>(done at previous notebook)</b></li>\n",
    "    <li>Cleansing <b>(done at previous notebook)</b></li>\n",
    "    <li>Formalization</li>\n",
    "    <li>Stemming</li>\n",
    "    <li>Stopword Removal</li>\n",
    "    <li>Tokenizing</li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalization (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 token pairs\n"
     ]
    }
   ],
   "source": [
    "formal_dict = {}\n",
    "with open('resources/formalization_dict.txt', 'r') as file:\n",
    "    i = 1\n",
    "    for row in file:\n",
    "        old, new = row.split('\\t')\n",
    "        i += 1\n",
    "        formal_dict[old] = new.lower().strip()\n",
    "\n",
    "print(f'There are {len(formal_dict)} token pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "formal_comment = []\n",
    "\n",
    "for comment in df.comment:\n",
    "    sentence = ' '+comment+' '\n",
    "    for false_word, true_word in formal_dict.items():\n",
    "        word = ' '+false_word+' '\n",
    "        sentence = sentence.replace(word, ' '+true_word+' ')\n",
    "    formal_comment.append(sentence)\n",
    "    \n",
    "print(f'We have {len(formal_comment)} comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming (Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk yang kecewa lo dengan update baru alih alih sempurna malah susah nasabah mandiri masuk saya agar kurang tindak tipu jahat waktu ada transaksi yang lebih rb rp maka bisa di tambah security upa kirim nomor verifikasi yang kirim ke nomor hp sms banking trus harus di masuk dalam applikasi mandiri online agar benar bahwa si nasabah sedang laku transaksi dengan demikian pasti tetap aman mohon perhati ya min terimakasih'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = StemmerFactory().create_stemmer()\n",
    "comment_stemmed = [stemmer.stem(formal_comment[i]) for i in range(df.shape[0])]\n",
    "\n",
    "comment_stemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' min bnyk yang kecewa lo dengan update terbaru alih alih penyempurnaan malah menyusahkan nasabah mandiri masukan saya agar mengurangi tindak penipuan kejahatan sewaktu ada transaksi yang lebih rb rp maka bisa di tambahkan security berupa pengiriman nomor verifikasi yang dikirimkan ke nomor hp sms banking trus harus di masukkan dalam applikasi mandiri online agar benar bahwa si nasabah sedang melakukan transaksi dengan demikian pasti tetap aman mohon diperhatikan ya min terimakasih '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_token(bad_token, dataset):\n",
    "    clean_dataset = []\n",
    "    for comment in dataset:\n",
    "        comment = ' '+comment+' '\n",
    "        for token in bad_token:\n",
    "            word = ' '+token+' '\n",
    "            comment = comment.replace(word, ' ')\n",
    "        \n",
    "        clean_dataset.append(comment.strip())\n",
    "    \n",
    "    assert len(dataset) == len(clean_dataset)\n",
    "    \n",
    "    return np.array(clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 stopword list\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\n",
    "    'yang', 'untuk', 'pada', 'antara', 'dan' , 'di', 'dari', 'hal', \n",
    "    'dalam', 'atau', 'kah', 'pun', 'dsb', 'dst', 'dll', 'toh', 'ya',\n",
    "    'saya', 'dengan', 'nya', 'ke', 'si', 'dah'\n",
    "]\n",
    "\n",
    "print(f'There are {len(stopwords)} stopword list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "clean_comment = []\n",
    "for comment in comment_stemmed:\n",
    "    for token in stopwords:\n",
    "        word = ' '+token+' '\n",
    "        comment = comment.replace(word, ' ')\n",
    "    if sentence.strip():\n",
    "        clean_comment.append(comment.strip())\n",
    "        \n",
    "print(f'We have {len(clean_comment)} comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk kecewa lo update baru alih alih sempurna malah susah nasabah mandiri masuk agar kurang tindak tipu jahat waktu ada transaksi lebih rb rp maka bisa tambah security upa kirim nomor verifikasi kirim nomor hp sms banking trus harus masuk applikasi mandiri online agar benar bahwa nasabah sedang laku transaksi demikian pasti tetap aman mohon perhati min terimakasih'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['min', 'bnyk', 'kecewa', 'lo', 'update', 'baru', 'alih', 'alih',\n",
       "       'sempurna', 'malah', 'susah', 'nasabah', 'mandiri', 'masuk',\n",
       "       'agar', 'kurang', 'tindak', 'tipu', 'jahat', 'waktu', 'ada',\n",
       "       'transaksi', 'lebih', 'rb', 'rp', 'maka', 'bisa', 'tambah',\n",
       "       'security', 'upa', 'kirim', 'nomor', 'verifikasi', 'kirim',\n",
       "       'nomor', 'hp', 'sms', 'banking', 'trus', 'harus', 'masuk',\n",
       "       'applikasi', 'mandiri', 'online', 'agar', 'benar', 'bahwa',\n",
       "       'nasabah', 'sedang', 'laku', 'transaksi', 'demikian', 'pasti',\n",
       "       'tetap', 'aman', 'mohon', 'perhati', 'min', 'terimakasih'],\n",
       "      dtype='<U11'),\n",
       "       array(['user', 'id', 'password', 'mesti', 'bank', 'gpplah', 'penting',\n",
       "       'aman', 'transaksi'], dtype='<U9')], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([np.array(comment.split()) for comment in clean_comment])\n",
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest + TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Important</h3>\n",
    "<ol>\n",
    "    <li><b>max_df</b>: occurred in too many documents(common word)</li>\n",
    "    <li><b>min_df</b>: occurred in too few documents (typo, alay)</li>\n",
    "    <li><b>n_estimators</b>: The number of trees in the forest of the model.</li>\n",
    "    <li><b>criterion</b>: The function to measure the quality of a split.</li>\n",
    "    <li><b>max_depth</b>: The max_depth parameter specifies the maximum depth of each tree. The default value for max_depth is None, which means that each tree will expand until every leaf is pure. A pure leaf is one where all of the data on the leaf comes from the same class.</li>\n",
    "    <li><b>min_samples_split</b>: The minimum number of samples required to split an internal leaf node. The default value for this parameter is 2, which means that an internal node must have at least two samples before it can be split to have a more specific classification.</li>\n",
    "    <li><b>min_samples_leaf</b>: The minimum number of samples required to be at a leaf node. The default value for this parameter is 1, which means that every leaf must have at least 1 sample that it classifies.</li>\n",
    "    <li><b>max_samples</b>: The number of samples to draw from X to train each base estimator. If None (default), then draw X.shape[0] samples.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27648"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.5, .6, .7 , .8, .9, 1.0]\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [20, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, .1]\n",
    "min_samples_leaf = [1, 5, 10]\n",
    "max_samples = [None, .6, .8]\n",
    "\n",
    "param_combinations = list(product(min_df, max_df, n_estimators, criterion,\n",
    "                                  max_depth, min_samples_split,\n",
    "                                  min_samples_leaf, max_samples))\n",
    "len(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============0===============\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "===============1===============\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "===============2===============\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "===============3===============\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "===============4===============\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "Train and evaluate 27648 permutation of model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "j=0\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    print(f'==============={i}===============')\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=param[0], max_df=param[1])\n",
    "        train_features = tfidf_vectorizer.fit_transform(features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(features[test_idx])\n",
    "        j+=1\n",
    "        if j%1000==0:\n",
    "            print(j)\n",
    "            \n",
    "        # train and evaluate\n",
    "        clf = RandomForestClassifier(n_estimators=param[2], criterion=param[3],\n",
    "                                     max_depth=param[4], min_samples_split=param[5],\n",
    "                                     min_samples_leaf=param[6], max_samples=param[7],\n",
    "                                     random_state=13)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "        \n",
    "print(f'Train and evaluate {len(param_combinations)} permutation of model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138240"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_combinations)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=None)</th>\n",
       "      <th>Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=None)</th>\n",
       "      <th>Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.6)</th>\n",
       "      <th>Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.6)</th>\n",
       "      <th>Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.8)</th>\n",
       "      <th>Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.8)</th>\n",
       "      <th>Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=None)</th>\n",
       "      <th>Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=None)</th>\n",
       "      <th>Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)</th>\n",
       "      <th>Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)</th>\n",
       "      <th>Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)</th>\n",
       "      <th>Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.8)</th>\n",
       "      <th>Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.8)</th>\n",
       "      <th>Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=None)</th>\n",
       "      <th>Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=None)</th>\n",
       "      <th>Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.6)</th>\n",
       "      <th>Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.6)</th>\n",
       "      <th>Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.8)</th>\n",
       "      <th>Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.8)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.900826</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.970424</td>\n",
       "      <td>0.821935</td>\n",
       "      <td>0.942460</td>\n",
       "      <td>0.722151</td>\n",
       "      <td>0.970411</td>\n",
       "      <td>0.840860</td>\n",
       "      <td>0.878147</td>\n",
       "      <td>0.736989</td>\n",
       "      <td>0.835646</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901233</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.904539</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.901233</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.901233</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.901233</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 13824 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=None)  \\\n",
       "Batch-1                                           0.975207                                                                                              \n",
       "Batch-2                                           0.983471                                                                                              \n",
       "Batch-3                                           0.967213                                                                                              \n",
       "Batch-4                                           0.950820                                                                                              \n",
       "Batch-5                                           0.975410                                                                                              \n",
       "Average                                           0.970424                                                                                              \n",
       "\n",
       "         Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=None)  \\\n",
       "Batch-1                                           0.838710                                                                                             \n",
       "Batch-2                                           0.870968                                                                                             \n",
       "Batch-3                                           0.866667                                                                                             \n",
       "Batch-4                                           0.866667                                                                                             \n",
       "Batch-5                                           0.666667                                                                                             \n",
       "Average                                           0.821935                                                                                             \n",
       "\n",
       "         Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.6)  \\\n",
       "Batch-1                                           0.950413                                                                                             \n",
       "Batch-2                                           0.950413                                                                                             \n",
       "Batch-3                                           0.942623                                                                                             \n",
       "Batch-4                                           0.901639                                                                                             \n",
       "Batch-5                                           0.967213                                                                                             \n",
       "Average                                           0.942460                                                                                             \n",
       "\n",
       "         Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.6)  \\\n",
       "Batch-1                                           0.903226                                                                                            \n",
       "Batch-2                                           0.774194                                                                                            \n",
       "Batch-3                                           0.766667                                                                                            \n",
       "Batch-4                                           0.533333                                                                                            \n",
       "Batch-5                                           0.633333                                                                                            \n",
       "Average                                           0.722151                                                                                            \n",
       "\n",
       "         Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.8)  \\\n",
       "Batch-1                                           0.975207                                                                                             \n",
       "Batch-2                                           0.975207                                                                                             \n",
       "Batch-3                                           0.967213                                                                                             \n",
       "Batch-4                                           0.950820                                                                                             \n",
       "Batch-5                                           0.983607                                                                                             \n",
       "Average                                           0.970411                                                                                             \n",
       "\n",
       "         Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=1, min_samples_leaf=1, max_samples=0.8)  \\\n",
       "Batch-1                                           0.903226                                                                                            \n",
       "Batch-2                                           0.967742                                                                                            \n",
       "Batch-3                                           0.900000                                                                                            \n",
       "Batch-4                                           0.833333                                                                                            \n",
       "Batch-5                                           0.600000                                                                                            \n",
       "Average                                           0.840860                                                                                            \n",
       "\n",
       "         Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=None)  \\\n",
       "Batch-1                                           0.900826                                                                                              \n",
       "Batch-2                                           0.768595                                                                                              \n",
       "Batch-3                                           0.844262                                                                                              \n",
       "Batch-4                                           0.918033                                                                                              \n",
       "Batch-5                                           0.959016                                                                                              \n",
       "Average                                           0.878147                                                                                              \n",
       "\n",
       "         Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=None)  \\\n",
       "Batch-1                                           0.806452                                                                                             \n",
       "Batch-2                                           0.645161                                                                                             \n",
       "Batch-3                                           0.733333                                                                                             \n",
       "Batch-4                                           0.900000                                                                                             \n",
       "Batch-5                                           0.600000                                                                                             \n",
       "Average                                           0.736989                                                                                             \n",
       "\n",
       "         Train Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)  \\\n",
       "Batch-1                                           0.867769                                                                                             \n",
       "Batch-2                                           0.876033                                                                                             \n",
       "Batch-3                                           0.729508                                                                                             \n",
       "Batch-4                                           0.770492                                                                                             \n",
       "Batch-5                                           0.934426                                                                                             \n",
       "Average                                           0.835646                                                                                             \n",
       "\n",
       "         Test Acc (min_df=0.0, max_df=0.5, n_estimators=10, criterion=gini, max_depth=20, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)  \\\n",
       "Batch-1                                           0.870968                                                                                            \n",
       "Batch-2                                           0.967742                                                                                            \n",
       "Batch-3                                           0.533333                                                                                            \n",
       "Batch-4                                           0.666667                                                                                            \n",
       "Batch-5                                           0.633333                                                                                            \n",
       "Average                                           0.734409                                                                                            \n",
       "\n",
       "         ...  \\\n",
       "Batch-1  ...   \n",
       "Batch-2  ...   \n",
       "Batch-3  ...   \n",
       "Batch-4  ...   \n",
       "Batch-5  ...   \n",
       "Average  ...   \n",
       "\n",
       "         Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)  \\\n",
       "Batch-1                                           0.876033                                                                                                   \n",
       "Batch-2                                           0.876033                                                                                                   \n",
       "Batch-3                                           0.893443                                                                                                   \n",
       "Batch-4                                           0.893443                                                                                                   \n",
       "Batch-5                                           0.967213                                                                                                   \n",
       "Average                                           0.901233                                                                                                   \n",
       "\n",
       "         Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.6)  \\\n",
       "Batch-1                                           1.000000                                                                                                  \n",
       "Batch-2                                           1.000000                                                                                                  \n",
       "Batch-3                                           0.933333                                                                                                  \n",
       "Batch-4                                           0.933333                                                                                                  \n",
       "Batch-5                                           0.633333                                                                                                  \n",
       "Average                                           0.900000                                                                                                  \n",
       "\n",
       "         Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.8)  \\\n",
       "Batch-1                                           0.884298                                                                                                   \n",
       "Batch-2                                           0.884298                                                                                                   \n",
       "Batch-3                                           0.893443                                                                                                   \n",
       "Batch-4                                           0.893443                                                                                                   \n",
       "Batch-5                                           0.967213                                                                                                   \n",
       "Average                                           0.904539                                                                                                   \n",
       "\n",
       "         Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=5, min_samples_leaf=5, max_samples=0.8)  \\\n",
       "Batch-1                                           1.000000                                                                                                  \n",
       "Batch-2                                           1.000000                                                                                                  \n",
       "Batch-3                                           0.933333                                                                                                  \n",
       "Batch-4                                           0.933333                                                                                                  \n",
       "Batch-5                                           0.633333                                                                                                  \n",
       "Average                                           0.900000                                                                                                  \n",
       "\n",
       "         Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=None)  \\\n",
       "Batch-1                                           0.876033                                                                                                      \n",
       "Batch-2                                           0.876033                                                                                                      \n",
       "Batch-3                                           0.893443                                                                                                      \n",
       "Batch-4                                           0.893443                                                                                                      \n",
       "Batch-5                                           0.967213                                                                                                      \n",
       "Average                                           0.901233                                                                                                      \n",
       "\n",
       "         Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=None)  \\\n",
       "Batch-1                                           1.000000                                                                                                     \n",
       "Batch-2                                           1.000000                                                                                                     \n",
       "Batch-3                                           0.933333                                                                                                     \n",
       "Batch-4                                           0.933333                                                                                                     \n",
       "Batch-5                                           0.633333                                                                                                     \n",
       "Average                                           0.900000                                                                                                     \n",
       "\n",
       "         Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.6)  \\\n",
       "Batch-1                                           0.876033                                                                                                     \n",
       "Batch-2                                           0.876033                                                                                                     \n",
       "Batch-3                                           0.893443                                                                                                     \n",
       "Batch-4                                           0.893443                                                                                                     \n",
       "Batch-5                                           0.967213                                                                                                     \n",
       "Average                                           0.901233                                                                                                     \n",
       "\n",
       "         Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.6)  \\\n",
       "Batch-1                                           1.000000                                                                                                    \n",
       "Batch-2                                           1.000000                                                                                                    \n",
       "Batch-3                                           0.933333                                                                                                    \n",
       "Batch-4                                           0.933333                                                                                                    \n",
       "Batch-5                                           0.633333                                                                                                    \n",
       "Average                                           0.900000                                                                                                    \n",
       "\n",
       "         Train Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.8)  \\\n",
       "Batch-1                                           0.876033                                                                                                     \n",
       "Batch-2                                           0.876033                                                                                                     \n",
       "Batch-3                                           0.893443                                                                                                     \n",
       "Batch-4                                           0.893443                                                                                                     \n",
       "Batch-5                                           0.967213                                                                                                     \n",
       "Average                                           0.901233                                                                                                     \n",
       "\n",
       "         Test Acc (min_df=0.3, max_df=1.0, n_estimators=200, criterion=entropy, max_depth=None, min_samples_split=10, min_samples_leaf=10, max_samples=0.8)  \n",
       "Batch-1                                           1.000000                                                                                                   \n",
       "Batch-2                                           1.000000                                                                                                   \n",
       "Batch-3                                           0.933333                                                                                                   \n",
       "Batch-4                                           0.933333                                                                                                   \n",
       "Batch-5                                           0.633333                                                                                                   \n",
       "Average                                           0.900000                                                                                                   \n",
       "\n",
       "[6 rows x 13824 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]})'] = test_history[i]\n",
    "    \n",
    "history_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_tfidf.loc['Average', test_col].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)</th>\n",
       "      <th>Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.876033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.893443</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.904512</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)  \\\n",
       "Batch-1                                           0.876033                                                                                                \n",
       "Batch-2                                           0.876033                                                                                                \n",
       "Batch-3                                           0.893443                                                                                                \n",
       "Batch-4                                           0.909836                                                                                                \n",
       "Batch-5                                           0.967213                                                                                                \n",
       "Average                                           0.904512                                                                                                \n",
       "\n",
       "         Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)  \n",
       "Batch-1                                           1.000000                                                                                              \n",
       "Batch-2                                           1.000000                                                                                              \n",
       "Batch-3                                           0.933333                                                                                              \n",
       "Batch-4                                           0.933333                                                                                              \n",
       "Batch-5                                           0.633333                                                                                              \n",
       "Average                                           0.900000                                                                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_tfidf[['Train Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)', 'Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We got <b>the best result</b> from Random Forest Model with \n",
    "<b>minimum</b> of word's occurrences is <b>30%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>50%</b> of total documents, \n",
    "with using <b> tree estimator</b> with <b> function </b>as measurement of quality of split,\n",
    "<b>max_depth = 1.0</b>, <b>min_samples_split = 1.0</b>, <b>min_samples_leaf = 1.0</b>\n",
    "and <b>max_samples = scale</b>,\n",
    "that is: <h3>90.00%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest +  Information Gain + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.5, .6, .7 , .8, .9, 1.0]\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [20, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, .1]\n",
    "min_samples_leaf = [1, 5, 10]\n",
    "max_samples = [None, .6, .8]\n",
    "ig_tresh = [1e-2, 1e-3, 1e-4, 1e-100]\n",
    "\n",
    "param_combinations = list(product(min_df, max_df, n_estimators, criterion,\n",
    "                                  max_depth, min_samples_split,\n",
    "                                  min_samples_leaf, max_samples, ig_tresh))\n",
    "len(param_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    ig_res = dict(zip(vectorizer.get_feature_names(),\n",
    "                      mutual_info_classif(train_count_features, train_labels, discrete_features=True)\n",
    "                   ))\n",
    "    ig_res = sorted(ig_res.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(i)\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        below_tresh = [ig[0] for ig in ig_res if ig[1] < param[-1]]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=param[0], max_df=param[1])\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "        \n",
    "        # train and evaluate\n",
    "        clf = RandomForestClassifier(n_estimators=param[2], criterion=param[3],\n",
    "                                     max_depth=param[4], min_samples_split=param[5],\n",
    "                                     min_samples_leaf=param[6], max_samples=param[7],\n",
    "                                     n_jobs=-1, random_state=13)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "        \n",
    "print(f'Train and evaluate {len(param_combinations)} permutation of model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, tresh={param_combinations[i][-1]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, tresh={param_combinations[i][-1]})'] = test_history[i]\n",
    "       \n",
    "history_ig_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_ig_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = [col for col in history_ig_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_ig_tfidf.loc['Average', test_col].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, tresh=0.01)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, tresh=0.01)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.867769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.867769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.894648</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, tresh=0.01)  \\\n",
       "Batch-1                                           0.867769                                                          \n",
       "Batch-2                                           0.867769                                                          \n",
       "Batch-3                                           0.885246                                                          \n",
       "Batch-4                                           0.885246                                                          \n",
       "Batch-5                                           0.967213                                                          \n",
       "Average                                           0.894648                                                          \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, tresh=0.01)  \n",
       "Batch-1                                           1.000000                                                        \n",
       "Batch-2                                           1.000000                                                        \n",
       "Batch-3                                           0.933333                                                        \n",
       "Batch-4                                           0.933333                                                        \n",
       "Batch-5                                           0.600000                                                        \n",
       "Average                                           0.893333                                                        "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_ig_tfidf[['Train Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None, tresh=0.0001)', 'Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None, tresh=0.0001)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got <b>the best result</b> from Random Forest Model with \n",
    "<b>information gain</b> as feature selection with <b>treshold = 0.01</b>,\n",
    "and another parameter from TF-IDF such as \n",
    "<b>minimum</b> of word's occurrences is <b>30%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>50%</b> of total documents, \n",
    "with using <b> tree estimator</b> with <b> function </b>as measurement of quality of split,\n",
    "<b>max_depth = 1.0</b>, <b>min_samples_split = 1.0</b>, <b>min_samples_leaf = 1.0</b>\n",
    "and <b>max_samples = scale</b>,\n",
    "that is: <h3>89.33%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest +  Chi Square + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 0.0, 0.5, 'linear', 0.001, 0.0),\n",
       " ((1, 1), 0.0, 0.5, 'linear', 0.001, 0.6),\n",
       " ((1, 1), 0.0, 0.5, 'linear', 0.001, 0.7)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.5, .6, .7 , .8, .9, 1.0]\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [20, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, .1]\n",
    "min_samples_leaf = [1, 5, 10]\n",
    "max_samples = [None, .6, .8]\n",
    "confidence_interval_list = [0.0, .6, .7, .8, .9, .95]\n",
    "\n",
    "param_combinations = list(product(min_df, max_df, n_estimators, criterion,\n",
    "                                  max_depth, min_samples_split,\n",
    "                                  min_samples_leaf, max_samples,\n",
    "                                  confidence_interval_list))\n",
    "len(param_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Train and evaluate 354240 permutation of model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    chi2_val, p_val = chi2(train_count_features, train_labels)\n",
    "    chi2_res = list(zip(vectorizer.get_feature_names(), chi2_val, p_val))\n",
    "    print(i)\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        # if p-value > alpha, then accept H0 (independent)\n",
    "        alpha = 1.0 - param[-1]\n",
    "        below_tresh = [word[0] for word in chi2_res if word[2] > alpha]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=param[0], max_df=param[1])\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "        \n",
    "        # train and evaluate\n",
    "        clf = RandomForestClassifier(n_estimators=param[2], criterion=param[3],\n",
    "                                     max_depth=param[4], min_samples_split=param[5],\n",
    "                                     min_samples_leaf=param[6], max_samples=param[7],\n",
    "                                     n_jobs=-1, random_state=13)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "        \n",
    "print(f'Train and evaluate {len(param_combinations)} permutation of model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.0)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.0)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.6)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.6)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.7)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.7)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.8)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.8)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.9)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.9)</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.6)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.6)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.7)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.7)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.8)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.8)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.9)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.9)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.95)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.811475</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.552688</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.552688</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.552688</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.552688</td>\n",
       "      <td>0.552635</td>\n",
       "      <td>0.552688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832137</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.832137</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.832137</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.832137</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.832137</td>\n",
       "      <td>0.827957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 141696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.0)  \\\n",
       "Batch-1                                           0.553719                                                    \n",
       "Batch-2                                           0.553719                                                    \n",
       "Batch-3                                           0.557377                                                    \n",
       "Batch-4                                           0.549180                                                    \n",
       "Batch-5                                           0.549180                                                    \n",
       "Average                                           0.552635                                                    \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.0)  \\\n",
       "Batch-1                                           0.548387                                                   \n",
       "Batch-2                                           0.548387                                                   \n",
       "Batch-3                                           0.533333                                                   \n",
       "Batch-4                                           0.566667                                                   \n",
       "Batch-5                                           0.566667                                                   \n",
       "Average                                           0.552688                                                   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.6)  \\\n",
       "Batch-1                                           0.553719                                                    \n",
       "Batch-2                                           0.553719                                                    \n",
       "Batch-3                                           0.557377                                                    \n",
       "Batch-4                                           0.549180                                                    \n",
       "Batch-5                                           0.549180                                                    \n",
       "Average                                           0.552635                                                    \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.6)  \\\n",
       "Batch-1                                           0.548387                                                   \n",
       "Batch-2                                           0.548387                                                   \n",
       "Batch-3                                           0.533333                                                   \n",
       "Batch-4                                           0.566667                                                   \n",
       "Batch-5                                           0.566667                                                   \n",
       "Average                                           0.552688                                                   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.7)  \\\n",
       "Batch-1                                           0.553719                                                    \n",
       "Batch-2                                           0.553719                                                    \n",
       "Batch-3                                           0.557377                                                    \n",
       "Batch-4                                           0.549180                                                    \n",
       "Batch-5                                           0.549180                                                    \n",
       "Average                                           0.552635                                                    \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.7)  \\\n",
       "Batch-1                                           0.548387                                                   \n",
       "Batch-2                                           0.548387                                                   \n",
       "Batch-3                                           0.533333                                                   \n",
       "Batch-4                                           0.566667                                                   \n",
       "Batch-5                                           0.566667                                                   \n",
       "Average                                           0.552688                                                   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.8)  \\\n",
       "Batch-1                                           0.553719                                                    \n",
       "Batch-2                                           0.553719                                                    \n",
       "Batch-3                                           0.557377                                                    \n",
       "Batch-4                                           0.549180                                                    \n",
       "Batch-5                                           0.549180                                                    \n",
       "Average                                           0.552635                                                    \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.8)  \\\n",
       "Batch-1                                           0.548387                                                   \n",
       "Batch-2                                           0.548387                                                   \n",
       "Batch-3                                           0.533333                                                   \n",
       "Batch-4                                           0.566667                                                   \n",
       "Batch-5                                           0.566667                                                   \n",
       "Average                                           0.552688                                                   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.9)  \\\n",
       "Batch-1                                           0.553719                                                    \n",
       "Batch-2                                           0.553719                                                    \n",
       "Batch-3                                           0.557377                                                    \n",
       "Batch-4                                           0.549180                                                    \n",
       "Batch-5                                           0.549180                                                    \n",
       "Average                                           0.552635                                                    \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, kernel=linear, C=0.001, confidence_interval=0.9)  \\\n",
       "Batch-1                                           0.548387                                                   \n",
       "Batch-2                                           0.548387                                                   \n",
       "Batch-3                                           0.533333                                                   \n",
       "Batch-4                                           0.566667                                                   \n",
       "Batch-5                                           0.566667                                                   \n",
       "Average                                           0.552688                                                   \n",
       "\n",
       "         ...  \\\n",
       "Batch-1  ...   \n",
       "Batch-2  ...   \n",
       "Batch-3  ...   \n",
       "Batch-4  ...   \n",
       "Batch-5  ...   \n",
       "Average  ...   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.6)  \\\n",
       "Batch-1                                           0.793388                                                          \n",
       "Batch-2                                           0.809917                                                          \n",
       "Batch-3                                           0.811475                                                          \n",
       "Batch-4                                           0.836066                                                          \n",
       "Batch-5                                           0.909836                                                          \n",
       "Average                                           0.832137                                                          \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.6)  \\\n",
       "Batch-1                                           0.935484                                                         \n",
       "Batch-2                                           0.870968                                                         \n",
       "Batch-3                                           0.933333                                                         \n",
       "Batch-4                                           0.833333                                                         \n",
       "Batch-5                                           0.566667                                                         \n",
       "Average                                           0.827957                                                         \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.7)  \\\n",
       "Batch-1                                           0.793388                                                          \n",
       "Batch-2                                           0.809917                                                          \n",
       "Batch-3                                           0.811475                                                          \n",
       "Batch-4                                           0.836066                                                          \n",
       "Batch-5                                           0.909836                                                          \n",
       "Average                                           0.832137                                                          \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.7)  \\\n",
       "Batch-1                                           0.935484                                                         \n",
       "Batch-2                                           0.870968                                                         \n",
       "Batch-3                                           0.933333                                                         \n",
       "Batch-4                                           0.833333                                                         \n",
       "Batch-5                                           0.566667                                                         \n",
       "Average                                           0.827957                                                         \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.8)  \\\n",
       "Batch-1                                           0.793388                                                          \n",
       "Batch-2                                           0.809917                                                          \n",
       "Batch-3                                           0.811475                                                          \n",
       "Batch-4                                           0.836066                                                          \n",
       "Batch-5                                           0.909836                                                          \n",
       "Average                                           0.832137                                                          \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.8)  \\\n",
       "Batch-1                                           0.935484                                                         \n",
       "Batch-2                                           0.870968                                                         \n",
       "Batch-3                                           0.933333                                                         \n",
       "Batch-4                                           0.833333                                                         \n",
       "Batch-5                                           0.566667                                                         \n",
       "Average                                           0.827957                                                         \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.9)  \\\n",
       "Batch-1                                           0.793388                                                          \n",
       "Batch-2                                           0.809917                                                          \n",
       "Batch-3                                           0.811475                                                          \n",
       "Batch-4                                           0.836066                                                          \n",
       "Batch-5                                           0.909836                                                          \n",
       "Average                                           0.832137                                                          \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.9)  \\\n",
       "Batch-1                                           0.935484                                                         \n",
       "Batch-2                                           0.870968                                                         \n",
       "Batch-3                                           0.933333                                                         \n",
       "Batch-4                                           0.833333                                                         \n",
       "Batch-5                                           0.566667                                                         \n",
       "Average                                           0.827957                                                         \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.95)  \\\n",
       "Batch-1                                           0.793388                                                           \n",
       "Batch-2                                           0.809917                                                           \n",
       "Batch-3                                           0.811475                                                           \n",
       "Batch-4                                           0.836066                                                           \n",
       "Batch-5                                           0.909836                                                           \n",
       "Average                                           0.832137                                                           \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, kernel=rbf, C=1.0, gamma=0.1, confidence_interval=0.95)  \n",
       "Batch-1                                           0.935484                                                         \n",
       "Batch-2                                           0.870968                                                         \n",
       "Batch-3                                           0.933333                                                         \n",
       "Batch-4                                           0.833333                                                         \n",
       "Batch-5                                           0.566667                                                         \n",
       "Average                                           0.827957                                                         \n",
       "\n",
       "[6 rows x 141696 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, confidence_interval={param_combinations[i][-1]*100}%)'] = train_history[i] \n",
    "    eval_history[f'Test Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, confidence_interval={param_combinations[i][-1]*100}%)'] = test_history[i]\n",
    "\n",
    "history_chi2_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                       'Batch-4', 'Batch-5', 'Average'])\n",
    "history_chi2_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, confidence_interval=0.0)'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_chi2_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_chi2_tfidf.loc['Average', test_col].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, confidence_interval=0.0)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, confidence_interval=0.0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.867769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.867769</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.894648</td>\n",
       "      <td>0.893333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, confidence_interval=0.0)  \\\n",
       "Batch-1                                           0.867769                                                                       \n",
       "Batch-2                                           0.867769                                                                       \n",
       "Batch-3                                           0.885246                                                                       \n",
       "Batch-4                                           0.885246                                                                       \n",
       "Batch-5                                           0.967213                                                                       \n",
       "Average                                           0.894648                                                                       \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, kernel=poly, C=1.0, degree=2, gamma=scale, confidence_interval=0.0)  \n",
       "Batch-1                                           1.000000                                                                     \n",
       "Batch-2                                           1.000000                                                                     \n",
       "Batch-3                                           0.933333                                                                     \n",
       "Batch-4                                           0.933333                                                                     \n",
       "Batch-5                                           0.600000                                                                     \n",
       "Average                                           0.893333                                                                     "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_chi2_tfidf[['Train Acc ()', 'Test Acc ()']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got <b>the best result</b> from Random Forest Model with \n",
    "<b>chi-square</b> as feature selection with <b>confidence interval = 0%</b>,\n",
    "and another parameter from TF-IDF such as \n",
    "<b>minimum</b> of word's occurrences is <b>30%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>50%</b> of total documents, \n",
    "with using <b> tree estimator</b> with <b> function </b>as measurement of quality of split,\n",
    "<b>max_depth = 1.0</b>, <b>min_samples_split = 1.0</b>, <b>min_samples_leaf = 1.0</b>\n",
    "and <b>max_samples = scale</b>,\n",
    "that is: <h3>89.33%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest +  Query Expansion Ranking + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_qer_score(features, labels):\n",
    "    \"\"\"\n",
    "    When a feature has low score, the diference between the probabilities \n",
    "    for the positive and negative classes is high; therefore the feature is \n",
    "    more class specifc and more valuable for classifcation process.\n",
    "    \n",
    "    score(f) = p(f) + q(f)/ |p(f) - q(f)|\n",
    "    p(f) = df(+) + .5/ n(+) + 1.0\n",
    "    q(f) = df(-) +.5/ n(-) + .5\n",
    "    df(+) --> document of f with positive class\n",
    "    n(+) ---> total document with positive class\n",
    "    \"\"\"\n",
    "\n",
    "    # create a dataset\n",
    "    dataset = [*zip(features, labels)]\n",
    "\n",
    "    # count frequency each class labels\n",
    "    label_counts = Counter(train_labels)\n",
    "\n",
    "    # extract all features\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit_transform(features)\n",
    "    feature_names = count_vectorizer.get_feature_names()\n",
    "\n",
    "    qer_score = {}\n",
    "    for word in feature_names:\n",
    "        doc_freq = {}\n",
    "\n",
    "        # count frequency each word at certain class labels\n",
    "        word = ' '+word+' '\n",
    "\n",
    "        for label in label_counts:\n",
    "            doc_freq[label] = 0\n",
    "\n",
    "        for doc in dataset:\n",
    "            sentence = ' '+doc[0]+' '\n",
    "            if word in sentence:\n",
    "                doc_freq[doc[1]] += 1\n",
    "\n",
    "        pf = (doc_freq[1] + .5) / (label_counts[1] + 1.0)\n",
    "        qf = (doc_freq[0] + .5) / (label_counts[0] + .5)\n",
    "        score = (pf + qf) / abs(pf - qf)\n",
    "        qer_score[word.strip()] = score\n",
    "        \n",
    "    return qer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110592"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.5, .6, .7 , .8, .9, 1.0]\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [20, 50, 100, None]\n",
    "min_samples_split = [2, 5, 10, .1]\n",
    "min_samples_leaf = [1, 5, 10]\n",
    "max_samples = [None, .6, .8]\n",
    "keep_data = [.1, .2, .3, .4]\n",
    "\n",
    "param_combinations = list(product(min_df, max_df, n_estimators, criterion,\n",
    "                                  max_depth, min_samples_split,\n",
    "                                  min_samples_leaf, max_samples,\n",
    "                                  keep_data))\n",
    "len(param_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============0===============\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "===============1===============\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "===============2===============\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "===============3===============\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "j=0\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    train_features = features[train_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    # calculate qer score\n",
    "    qer_score = calculate_qer_score(train_features, train_labels)\n",
    "    size_train_features = len(qer_score)\n",
    "    sorted_qer_score = sorted(qer_score.items(), key=lambda x: x[1])\n",
    "    print(f'==============={i}===============')\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        # create new features with selected good feature with qer score\n",
    "        boundary_idx = round(size_train_features * param[-1])\n",
    "        below_tresh = [word[0] for word in sorted_qer_score[boundary_idx:]]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(min_df=param[0], max_df=param[1])\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "        j+=1\n",
    "        if j%1000==0:\n",
    "            print(j)\n",
    "        # train and evaluate\n",
    "        clf = RandomForestClassifier(n_estimators=param[2], criterion=param[3],\n",
    "                                     max_depth=param[4], min_samples_split=param[5],\n",
    "                                     min_samples_leaf=param[6], max_samples=param[7],\n",
    "                                     random_state=13)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "        \n",
    "print(f'Train and evaluate {len(param_combinations)} permutation of model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552960"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_combinations)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, keep_data={param_combinations[i][-1]*100}%)'] = train_history[i] \n",
    "    eval_history[f'Test Acc (min_df={param_combinations[i][0]}, max_df={param_combinations[i][1]}, n_estimators={param_combinations[i][2]}, criterion={param_combinations[i][3]}, max_depth={param_combinations[i][4]}, min_samples_split={param_combinations[i][6]}, min_samples_leaf={param_combinations[i][6]}, max_samples={param_combinations[i][7]}, keep_data={param_combinations[i][-1]*100}%)'] = test_history[i]\n",
    "       \n",
    "    \n",
    "history_qer = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_qer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_col = [col for col in history_qer.columns if col.startswith('Test')]\n",
    "test_col[history_qer.loc['Average', test_col].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_qer[['Train Acc ()', 'Test Acc ()']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_qer[['Train Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None, keep_data=100.0%)', 'Test Acc (min_df=0.1, max_df=0.5, n_estimators=50, criterion=gini, max_depth=20, min_samples_split=10, min_samples_leaf=10, max_samples=None, keep_data=100.0%)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got <b>the best result</b> from Random Forest Model with <b>Query Expansion Ranking</b> \n",
    "as feature selection with we <b>keep 10% of dataset's features</b>,\n",
    "and another parameter from TF-IDF such as \n",
    "<b>minimum</b> of word's occurrences is <b>30%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>50%</b> of total documents, \n",
    "with using <b> tree estimator</b> with <b> function </b>as measurement of quality of split,\n",
    "<b>max_depth = 1.0</b>, <b>min_samples_split = 1.0</b>, <b>min_samples_leaf = 1.0</b>\n",
    "and <b>max_samples = scale</b>,\n",
    "that is: <h3>89.33%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model + Feature Selection</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM + TF-IDF</td>\n",
       "      <td>89.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM + IG + TF-IDF</td>\n",
       "      <td>89.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM + CHI2 + TF-IDF</td>\n",
       "      <td>89.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM + QER + TF-IDF</td>\n",
       "      <td>89.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model + Feature Selection  Test Accuracy\n",
       "0              SVM + TF-IDF          89.33\n",
       "1         SVM + IG + TF-IDF          89.33\n",
       "2       SVM + CHI2 + TF-IDF          89.33\n",
       "3        SVM + QER + TF-IDF          89.33"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['RF + TF-IDF', 'RF + IG + TF-IDF', \n",
    "          'RF + CHI2 + TF-IDF', 'RF + QER + TF-IDF']\n",
    "test_accuracy_avg = [90.00, 90.00, 89.33, 90.00]\n",
    "\n",
    "res_df = pd.DataFrame({'Model + Feature Selection': models, 'Test Accuracy': test_accuracy_avg})\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 95)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "\n",
    "ax = sns.barplot(x='Test Accuracy', y='Model + Feature Selection', data=res_df)\n",
    "ax.set_xlabel('Test Accuracy (100%)')\n",
    "plt.xticks([i*10 for i in range(11)])\n",
    "plt.xlim([70, 95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 0.0, 0.5, 'linear', 1.0, 0.1),\n",
       " ((1, 1), 0.0, 0.5, 'linear', 1.0, 0.2),\n",
       " ((1, 1), 0.0, 0.5, 'linear', 1.0, 0.3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['Naive Bayes', 'KNN', 'SVM',\n",
    "          'Maximum Entropy', 'Random Forest']\n",
    "test_accuracy_avg = [89.03, 90.00, 90.00, 84.84, 90.00]\n",
    "\n",
    "final_res_df = pd.DataFrame({'Model': models, 'Test Accuracy': test_accuracy_avg})\n",
    "final_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "\n",
    "ax = sns.barplot(x='Test Accuracy', y='Model', data=final_res_df)\n",
    "ax.set_xlabel('Test Accuracy (100%)')\n",
    "plt.xticks([i*10 for i in range(11)])\n",
    "plt.xlim([70, 95])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
