{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataset/Data 1.xlsx', names=['comment', 'polarity'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min bnyk yg kecewa lo dgn update terbaru alih ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user id password mesti ke bank ya gpplah yg pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saat transfer kadang ada muncul keterangan kon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>begitu saya update dan no tlpn saya statusnya ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tolong tambahkan fitur fingerprint atau face r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  polarity\n",
       "0  min bnyk yg kecewa lo dgn update terbaru alih ...         1\n",
       "1  user id password mesti ke bank ya gpplah yg pe...         1\n",
       "2  saat transfer kadang ada muncul keterangan kon...         1\n",
       "3  begitu saya update dan no tlpn saya statusnya ...         1\n",
       "4  tolong tambahkan fitur fingerprint atau face r...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<ol>\n",
    "    <li>Case folding <b>(done at previous notebook)</b></li>\n",
    "    <li>Cleansing <b>(done at previous notebook)</b></li>\n",
    "    <li>Formalization</li>\n",
    "    <li>Stemming</li>\n",
    "    <li>Stopword Removal</li>\n",
    "    <li>Tokenizing</li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalization (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 token pairs\n"
     ]
    }
   ],
   "source": [
    "formal_dict = {}\n",
    "with open('resources/formalization_dict.txt', 'r') as file:\n",
    "    i = 1\n",
    "    for row in file:\n",
    "        old, new = row.split('\\t')\n",
    "        i += 1\n",
    "        formal_dict[old] = new.lower().strip()\n",
    "\n",
    "print(f'There are {len(formal_dict)} token pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "formal_comment = []\n",
    "\n",
    "for comment in df.comment:\n",
    "    sentence = ' '+comment+' '\n",
    "    for false_word, true_word in formal_dict.items():\n",
    "        word = ' '+false_word+' '\n",
    "        sentence = sentence.replace(word, ' '+true_word+' ')\n",
    "    formal_comment.append(sentence)\n",
    "    \n",
    "print(f'We have {len(formal_comment)} comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming (Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk yang kecewa lo dengan update baru alih alih sempurna malah susah nasabah mandiri masuk saya agar kurang tindak tipu jahat waktu ada transaksi yang lebih rb rp maka bisa di tambah security upa kirim nomor verifikasi yang kirim ke nomor hp sms banking trus harus di masuk dalam applikasi mandiri online agar benar bahwa si nasabah sedang laku transaksi dengan demikian pasti tetap aman mohon perhati ya min terimakasih'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = StemmerFactory().create_stemmer()\n",
    "comment_stemmed = [stemmer.stem(formal_comment[i]) for i in range(df.shape[0])]\n",
    "\n",
    "comment_stemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' min bnyk yang kecewa lo dengan update terbaru alih alih penyempurnaan malah menyusahkan nasabah mandiri masukan saya agar mengurangi tindak penipuan kejahatan sewaktu ada transaksi yang lebih rb rp maka bisa di tambahkan security berupa pengiriman nomor verifikasi yang dikirimkan ke nomor hp sms banking trus harus di masukkan dalam applikasi mandiri online agar benar bahwa si nasabah sedang melakukan transaksi dengan demikian pasti tetap aman mohon diperhatikan ya min terimakasih '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 stopword list\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\n",
    "    'yang', 'untuk', 'pada', 'antara', 'dan' , 'di', 'dari', 'hal', \n",
    "    'dalam', 'atau', 'kah', 'pun', 'dsb', 'dst', 'dll', 'toh', 'ya',\n",
    "    'saya', 'dengan', 'nya', 'ke', 'si', 'dah'\n",
    "]\n",
    "\n",
    "print(f'There are {len(stopwords)} stopword list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "clean_comment = []\n",
    "for comment in comment_stemmed:\n",
    "    for token in stopwords:\n",
    "        word = ' '+token+' '\n",
    "        comment = comment.replace(word, ' ')\n",
    "    if sentence.strip():\n",
    "        clean_comment.append(comment.strip())\n",
    "        \n",
    "print(f'We have {len(clean_comment)} comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk kecewa lo update baru alih alih sempurna malah susah nasabah mandiri masuk agar kurang tindak tipu jahat waktu ada transaksi lebih rb rp maka bisa tambah security upa kirim nomor verifikasi kirim nomor hp sms banking trus harus masuk applikasi mandiri online agar benar bahwa nasabah sedang laku transaksi demikian pasti tetap aman mohon perhati min terimakasih'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['min', 'bnyk', 'kecewa', 'lo', 'update', 'baru', 'alih', 'alih',\n",
       "       'sempurna', 'malah', 'susah', 'nasabah', 'mandiri', 'masuk',\n",
       "       'agar', 'kurang', 'tindak', 'tipu', 'jahat', 'waktu', 'ada',\n",
       "       'transaksi', 'lebih', 'rb', 'rp', 'maka', 'bisa', 'tambah',\n",
       "       'security', 'upa', 'kirim', 'nomor', 'verifikasi', 'kirim',\n",
       "       'nomor', 'hp', 'sms', 'banking', 'trus', 'harus', 'masuk',\n",
       "       'applikasi', 'mandiri', 'online', 'agar', 'benar', 'bahwa',\n",
       "       'nasabah', 'sedang', 'laku', 'transaksi', 'demikian', 'pasti',\n",
       "       'tetap', 'aman', 'mohon', 'perhati', 'min', 'terimakasih'],\n",
       "      dtype='<U11'),\n",
       "       array(['user', 'id', 'password', 'mesti', 'bank', 'gpplah', 'penting',\n",
       "       'aman', 'transaksi'], dtype='<U9')], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([np.array(comment.split()) for comment in clean_comment])\n",
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Warning</b>: Don't run this code if you already have separated dataset before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.552632\n",
       "1    0.447368\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(df.polarity)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0    0.694215\n",
      "1    0.305785\n",
      "Name: polarity, dtype: float64\n",
      "Test 1    1.0\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 0    0.628099\n",
      "1    0.371901\n",
      "Name: polarity, dtype: float64\n",
      "Test 1    0.741935\n",
      "0    0.258065\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 1    0.557377\n",
      "0    0.442623\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    1.0\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 0    0.508197\n",
      "1    0.491803\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    0.733333\n",
      "1    0.266667\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 1    0.508197\n",
      "0    0.491803\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    0.8\n",
      "1    0.2\n",
      "Name: polarity, dtype: float64\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=0)\n",
    "for train, test in kfold.split(features, labels):\n",
    "    print('Train', df.iloc[train, 1].value_counts() / len(train))\n",
    "    print('Test', df.iloc[test, 1].value_counts() / len(test))\n",
    "    print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1\n",
      " 0    0.553719\n",
      "1    0.446281\n",
      "Name: polarity, dtype: float64\n",
      "test 1\n",
      " 0    0.548387\n",
      "1    0.451613\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 2\n",
      " 0    0.553719\n",
      "1    0.446281\n",
      "Name: polarity, dtype: float64\n",
      "test 2\n",
      " 0    0.548387\n",
      "1    0.451613\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 3\n",
      " 0    0.557377\n",
      "1    0.442623\n",
      "Name: polarity, dtype: float64\n",
      "test 3\n",
      " 0    0.533333\n",
      "1    0.466667\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 4\n",
      " 0    0.54918\n",
      "1    0.45082\n",
      "Name: polarity, dtype: float64\n",
      "test 4\n",
      " 0    0.566667\n",
      "1    0.433333\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 5\n",
      " 0    0.54918\n",
      "1    0.45082\n",
      "Name: polarity, dtype: float64\n",
      "test 5\n",
      " 0    0.566667\n",
      "1    0.433333\n",
      "Name: polarity, dtype: float64\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "# split and save index of each batch train-test\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "\n",
    "i = 1\n",
    "for train, test in skf.split(df.comment, df.polarity):\n",
    "    np.save(f'dataset/train_{i}', train)\n",
    "    np.save(f'dataset/test_{i}', test)\n",
    "    print(f'train {i}\\n', df.iloc[train, 1].value_counts()/len(train))\n",
    "    print(f'test {i}\\n', df.iloc[test, 1].value_counts()/len(test))\n",
    "    print('===================')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "smoothing_parameter = [1.0, .1, .01, .001]\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    # \n",
    "    train_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_features = vectorizer.transform(features[test_idx])\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    for param in smoothing_parameter:\n",
    "        clf = MultinomialNB(alpha=param)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "        \n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(smoothing_parameter)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (a=1.0)</th>\n",
       "      <th>Test Acc (a=1.0)</th>\n",
       "      <th>Train Acc (a=0.1)</th>\n",
       "      <th>Test Acc (a=0.1)</th>\n",
       "      <th>Train Acc (a=0.01)</th>\n",
       "      <th>Test Acc (a=0.01)</th>\n",
       "      <th>Train Acc (a=0.001)</th>\n",
       "      <th>Test Acc (a=0.001)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.968731</td>\n",
       "      <td>0.722366</td>\n",
       "      <td>0.985205</td>\n",
       "      <td>0.676989</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.637849</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.618065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (a=1.0)  Test Acc (a=1.0)  Train Acc (a=0.1)  \\\n",
       "Batch-1           0.975207          0.741935           1.000000   \n",
       "Batch-2           0.950413          0.903226           0.975207   \n",
       "Batch-3           0.975410          0.800000           0.975410   \n",
       "Batch-4           0.967213          0.766667           0.983607   \n",
       "Batch-5           0.975410          0.400000           0.991803   \n",
       "Average           0.968731          0.722366           0.985205   \n",
       "\n",
       "         Test Acc (a=0.1)  Train Acc (a=0.01)  Test Acc (a=0.01)  \\\n",
       "Batch-1          0.677419            1.000000           0.709677   \n",
       "Batch-2          0.774194            0.975207           0.612903   \n",
       "Batch-3          0.766667            0.983607           0.733333   \n",
       "Batch-4          0.833333            0.991803           0.833333   \n",
       "Batch-5          0.333333            0.991803           0.300000   \n",
       "Average          0.676989            0.988484           0.637849   \n",
       "\n",
       "         Train Acc (a=0.001)  Test Acc (a=0.001)  \n",
       "Batch-1             1.000000            0.677419  \n",
       "Batch-2             0.975207            0.612903  \n",
       "Batch-3             0.983607            0.700000  \n",
       "Batch-4             0.991803            0.800000  \n",
       "Batch-5             0.991803            0.300000  \n",
       "Average             0.988484            0.618065  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (a={smoothing_parameter[i]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (a={smoothing_parameter[i]})'] = test_history[i]\n",
    "    \n",
    "history = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                            'Batch-4', 'Batch-5', 'Average'])\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the lower the alpha value, the lower the accuracy value on the test data (Overfitting)\n",
    "\n",
    "We got <b>the best result</b> from Multinomial Naive Bayes Model with <b>alpha = 1.0</b> that is: <h3>72.24%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Important</h3>\n",
    "<ol>\n",
    "    <li>ngram_range</li>\n",
    "    <li>max_df: occurred in too many documents(common word)</li>\n",
    "    <li>min_df: occurred in too few documents (typo, alay)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 0.0, 0.4), ((1, 1), 0.0, 0.5), ((1, 1), 0.0, 0.6)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram = [(1, 1), (1, 2), (1, 3)]\n",
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.4, .5, .6, .7 , .8, .9, 1.0]\n",
    "\n",
    "param_combinations = list(product(ngram, min_df, max_df))\n",
    "param_combinations[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=param[0], min_df=param[1], max_df=param[2])\n",
    "        train_features = tfidf_vectorizer.fit_transform(features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(features[test_idx])\n",
    "        \n",
    "        # train and evaluate\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "        \n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "        \n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.4</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.4</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.8</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.6</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.6</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.7</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.7</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.8</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.8</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.4  \\\n",
       "Batch-1                                          0.991736   \n",
       "Batch-2                                          0.975207   \n",
       "Batch-3                                          0.975410   \n",
       "Batch-4                                          0.975410   \n",
       "Batch-5                                          0.959016   \n",
       "Average                                          0.975356   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.4  \\\n",
       "Batch-1                                         0.709677   \n",
       "Batch-2                                         0.774194   \n",
       "Batch-3                                         0.700000   \n",
       "Batch-4                                         0.800000   \n",
       "Batch-5                                         0.466667   \n",
       "Average                                         0.690108   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5  \\\n",
       "Batch-1                                          0.991736   \n",
       "Batch-2                                          0.975207   \n",
       "Batch-3                                          0.975410   \n",
       "Batch-4                                          0.975410   \n",
       "Batch-5                                          0.959016   \n",
       "Average                                          0.975356   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5  \\\n",
       "Batch-1                                         0.709677   \n",
       "Batch-2                                         0.774194   \n",
       "Batch-3                                         0.700000   \n",
       "Batch-4                                         0.733333   \n",
       "Batch-5                                         0.533333   \n",
       "Average                                         0.690108   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6  \\\n",
       "Batch-1                                          0.991736   \n",
       "Batch-2                                          0.975207   \n",
       "Batch-3                                          0.975410   \n",
       "Batch-4                                          0.975410   \n",
       "Batch-5                                          0.959016   \n",
       "Average                                          0.975356   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6  \\\n",
       "Batch-1                                         0.709677   \n",
       "Batch-2                                         0.774194   \n",
       "Batch-3                                         0.700000   \n",
       "Batch-4                                         0.733333   \n",
       "Batch-5                                         0.533333   \n",
       "Average                                         0.690108   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7  \\\n",
       "Batch-1                                          0.991736   \n",
       "Batch-2                                          0.975207   \n",
       "Batch-3                                          0.975410   \n",
       "Batch-4                                          0.975410   \n",
       "Batch-5                                          0.959016   \n",
       "Average                                          0.975356   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7  \\\n",
       "Batch-1                                         0.709677   \n",
       "Batch-2                                         0.774194   \n",
       "Batch-3                                         0.700000   \n",
       "Batch-4                                         0.733333   \n",
       "Batch-5                                         0.533333   \n",
       "Average                                         0.690108   \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.8  \\\n",
       "Batch-1                                          0.991736   \n",
       "Batch-2                                          0.975207   \n",
       "Batch-3                                          0.975410   \n",
       "Batch-4                                          0.975410   \n",
       "Batch-5                                          0.959016   \n",
       "Average                                          0.975356   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.8  ...  \\\n",
       "Batch-1                                         0.709677  ...   \n",
       "Batch-2                                         0.774194  ...   \n",
       "Batch-3                                         0.700000  ...   \n",
       "Batch-4                                         0.733333  ...   \n",
       "Batch-5                                         0.533333  ...   \n",
       "Average                                         0.690108  ...   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.6  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.6  \\\n",
       "Batch-1                                         0.935484   \n",
       "Batch-2                                         0.935484   \n",
       "Batch-3                                         0.933333   \n",
       "Batch-4                                         0.900000   \n",
       "Batch-5                                         0.600000   \n",
       "Average                                         0.860860   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.7  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.7  \\\n",
       "Batch-1                                         0.935484   \n",
       "Batch-2                                         0.935484   \n",
       "Batch-3                                         0.933333   \n",
       "Batch-4                                         0.900000   \n",
       "Batch-5                                         0.600000   \n",
       "Average                                         0.860860   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.8  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.8  \\\n",
       "Batch-1                                         0.935484   \n",
       "Batch-2                                         0.935484   \n",
       "Batch-3                                         0.933333   \n",
       "Batch-4                                         0.900000   \n",
       "Batch-5                                         0.600000   \n",
       "Average                                         0.860860   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9  \\\n",
       "Batch-1                                         0.935484   \n",
       "Batch-2                                         0.935484   \n",
       "Batch-3                                         0.933333   \n",
       "Batch-4                                         0.900000   \n",
       "Batch-5                                         0.600000   \n",
       "Average                                         0.860860   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0  \n",
       "Batch-1                                         0.935484  \n",
       "Batch-2                                         0.935484  \n",
       "Batch-3                                         0.933333  \n",
       "Batch-4                                         0.900000  \n",
       "Batch-5                                         0.600000  \n",
       "Average                                         0.860860  \n",
       "\n",
       "[6 rows x 168 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}'] = train_history[i] \n",
    "    eval_history[f'Test Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}'] = test_history[i]\n",
    "    \n",
    "history_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_tfidf.loc['Average', test_col].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5  \\\n",
       "Batch-1                                          0.834711   \n",
       "Batch-2                                          0.826446   \n",
       "Batch-3                                          0.860656   \n",
       "Batch-4                                          0.868852   \n",
       "Batch-5                                          0.868852   \n",
       "Average                                          0.851904   \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5  \n",
       "Batch-1                                         0.935484  \n",
       "Batch-2                                         0.935484  \n",
       "Batch-3                                         0.933333  \n",
       "Batch-4                                         0.900000  \n",
       "Batch-5                                         0.600000  \n",
       "Average                                         0.860860  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_tfidf[['Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5', 'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We got <b>the best result</b> from Multinomial Naive Bayes Model with \n",
    "<b>minimum</b> of word's occurrences is <b>30%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>50%</b> of total documents, \n",
    "and <b>only use 1 gram</b> that is: <h3>86.01%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes +  Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aman', 0.4302862055362001),\n",
       " ('tidak', 0.3201787480418658),\n",
       " ('bisa', 0.3150763461017261),\n",
       " ('ini', 0.24675401200991912),\n",
       " ('aplikasi', 0.20636826950745146)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = np.load(f'dataset/train_1.npy')\n",
    "test_idx = np.load(f'dataset/test_1.npy')\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "ig_res = dict(zip(vectorizer.get_feature_names(),\n",
    "                  mutual_info_classif(train_count_features, train_labels, discrete_features=True)\n",
    "               ))\n",
    "ig_res = sorted(ig_res.items(), key=lambda x: x[1], reverse=True)\n",
    "ig_res[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_res[-1][1] > 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_token(bad_token, dataset):\n",
    "    clean_dataset = []\n",
    "    for comment in dataset:\n",
    "        comment = ' '+comment+' '\n",
    "        for token in bad_token:\n",
    "            word = ' '+token+' '\n",
    "            comment = comment.replace(word, ' ')\n",
    "        \n",
    "        clean_dataset.append(comment.strip())\n",
    "        \n",
    "    return np.array(clean_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "ig_tresh = [1e-1, 1e-2, 1e-3]\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    ig_res = dict(zip(vectorizer.get_feature_names(),\n",
    "                      mutual_info_classif(train_count_features, train_labels, discrete_features=True)\n",
    "                   ))\n",
    "    ig_res = sorted(ig_res.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    below_tresh = []\n",
    "    for j in range(len(ig_tresh)):\n",
    "        below_tresh.append([ig[0] for ig in ig_res if ig[1] < ig_tresh[j]])\n",
    "    \n",
    "        new_features = remove_token(below_tresh[j], features)\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "\n",
    "        # train and evaluate\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(ig_tresh)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (tresh=0.01)</th>\n",
       "      <th>Test Acc (tresh=0.01)</th>\n",
       "      <th>Train Acc (tresh=0.001)</th>\n",
       "      <th>Test Acc (tresh=0.001)</th>\n",
       "      <th>Train Acc (tresh=0.0001)</th>\n",
       "      <th>Test Acc (tresh=0.0001)</th>\n",
       "      <th>Train Acc (tresh=1e-100)</th>\n",
       "      <th>Test Acc (tresh=1e-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.953922</td>\n",
       "      <td>0.703011</td>\n",
       "      <td>0.980287</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.977009</td>\n",
       "      <td>0.683441</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (tresh=0.01)  Test Acc (tresh=0.01)  \\\n",
       "Batch-1                0.950413               0.677419   \n",
       "Batch-2                0.942149               0.870968   \n",
       "Batch-3                0.967213               0.766667   \n",
       "Batch-4                0.934426               0.733333   \n",
       "Batch-5                0.975410               0.466667   \n",
       "Average                0.953922               0.703011   \n",
       "\n",
       "         Train Acc (tresh=0.001)  Test Acc (tresh=0.001)  \\\n",
       "Batch-1                 1.000000                0.677419   \n",
       "Batch-2                 0.975207                0.806452   \n",
       "Batch-3                 0.975410                0.733333   \n",
       "Batch-4                 0.983607                0.733333   \n",
       "Batch-5                 0.967213                0.533333   \n",
       "Average                 0.980287                0.696774   \n",
       "\n",
       "         Train Acc (tresh=0.0001)  Test Acc (tresh=0.0001)  \\\n",
       "Batch-1                  1.000000                 0.709677   \n",
       "Batch-2                  0.975207                 0.774194   \n",
       "Batch-3                  0.975410                 0.700000   \n",
       "Batch-4                  0.975410                 0.766667   \n",
       "Batch-5                  0.959016                 0.466667   \n",
       "Average                  0.977009                 0.683441   \n",
       "\n",
       "         Train Acc (tresh=1e-100)  Test Acc (tresh=1e-100)  \n",
       "Batch-1                  0.991736                 0.709677  \n",
       "Batch-2                  0.975207                 0.774194  \n",
       "Batch-3                  0.975410                 0.700000  \n",
       "Batch-4                  0.975410                 0.733333  \n",
       "Batch-5                  0.959016                 0.533333  \n",
       "Average                  0.975356                 0.690108  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (tresh={ig_tresh[i]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (tresh={ig_tresh[i]})'] = test_history[i]\n",
    "    \n",
    "history_ig = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare with model that <b>not using information gain</b>, we get <b>72.24%</b> for test accuracy.\n",
    "And with <b>using information gain</b> with the best parameter we get:\n",
    "<h3>70.3%</h3>\n",
    "\n",
    "> Recommend to <b>not use</b> INFORMATION GAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes +  Information Gain + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 0.0, 0.5, 0.01),\n",
       " ((1, 1), 0.0, 0.5, 0.001),\n",
       " ((1, 1), 0.0, 0.5, 0.0001)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram = [(1, 1), (1, 2), (1, 3)]\n",
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.5, .6, .7 , .8, .9, 1.0]\n",
    "ig_tresh = [1e-2, 1e-3, 1e-4, 1e-100]\n",
    "\n",
    "param_combinations = list(product(ngram, min_df, max_df, ig_tresh))\n",
    "param_combinations[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    ig_res = dict(zip(vectorizer.get_feature_names(),\n",
    "                      mutual_info_classif(train_count_features, train_labels, discrete_features=True)\n",
    "                   ))\n",
    "    ig_res = sorted(ig_res.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        below_tresh = [ig[0] for ig in ig_res if ig[1] < param[-1]]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=param[0], min_df=param[1], max_df=param[2])\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "\n",
    "        # train and evaluate\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "        \n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.01</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.01</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.001</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.001</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.0001</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.0001</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=1e-100</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=1e-100</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6, tresh=0.01</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6, tresh=0.01</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9, tresh=1e-100</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9, tresh=1e-100</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.01</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.01</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.001</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.001</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.0001</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.0001</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=1e-100</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=1e-100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.953922</td>\n",
       "      <td>0.703011</td>\n",
       "      <td>0.980287</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.977009</td>\n",
       "      <td>0.683441</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.953922</td>\n",
       "      <td>0.703011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.01  \\\n",
       "Batch-1                                           0.950413              \n",
       "Batch-2                                           0.942149              \n",
       "Batch-3                                           0.967213              \n",
       "Batch-4                                           0.934426              \n",
       "Batch-5                                           0.975410              \n",
       "Average                                           0.953922              \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.01  \\\n",
       "Batch-1                                           0.677419             \n",
       "Batch-2                                           0.870968             \n",
       "Batch-3                                           0.766667             \n",
       "Batch-4                                           0.733333             \n",
       "Batch-5                                           0.466667             \n",
       "Average                                           0.703011             \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.001  \\\n",
       "Batch-1                                           1.000000               \n",
       "Batch-2                                           0.975207               \n",
       "Batch-3                                           0.975410               \n",
       "Batch-4                                           0.983607               \n",
       "Batch-5                                           0.967213               \n",
       "Average                                           0.980287               \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.001  \\\n",
       "Batch-1                                           0.677419              \n",
       "Batch-2                                           0.806452              \n",
       "Batch-3                                           0.733333              \n",
       "Batch-4                                           0.733333              \n",
       "Batch-5                                           0.533333              \n",
       "Average                                           0.696774              \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.0001  \\\n",
       "Batch-1                                           1.000000                \n",
       "Batch-2                                           0.975207                \n",
       "Batch-3                                           0.975410                \n",
       "Batch-4                                           0.975410                \n",
       "Batch-5                                           0.959016                \n",
       "Average                                           0.977009                \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=0.0001  \\\n",
       "Batch-1                                           0.709677               \n",
       "Batch-2                                           0.774194               \n",
       "Batch-3                                           0.700000               \n",
       "Batch-4                                           0.766667               \n",
       "Batch-5                                           0.466667               \n",
       "Average                                           0.683441               \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=1e-100  \\\n",
       "Batch-1                                           0.991736                \n",
       "Batch-2                                           0.975207                \n",
       "Batch-3                                           0.975410                \n",
       "Batch-4                                           0.975410                \n",
       "Batch-5                                           0.959016                \n",
       "Average                                           0.975356                \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.5, tresh=1e-100  \\\n",
       "Batch-1                                           0.709677               \n",
       "Batch-2                                           0.774194               \n",
       "Batch-3                                           0.700000               \n",
       "Batch-4                                           0.733333               \n",
       "Batch-5                                           0.533333               \n",
       "Average                                           0.690108               \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6, tresh=0.01  \\\n",
       "Batch-1                                           0.950413              \n",
       "Batch-2                                           0.942149              \n",
       "Batch-3                                           0.967213              \n",
       "Batch-4                                           0.934426              \n",
       "Batch-5                                           0.975410              \n",
       "Average                                           0.953922              \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.6, tresh=0.01  ...  \\\n",
       "Batch-1                                           0.677419            ...   \n",
       "Batch-2                                           0.870968            ...   \n",
       "Batch-3                                           0.766667            ...   \n",
       "Batch-4                                           0.733333            ...   \n",
       "Batch-5                                           0.466667            ...   \n",
       "Average                                           0.703011            ...   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9, tresh=1e-100  \\\n",
       "Batch-1                                           0.834711                \n",
       "Batch-2                                           0.826446                \n",
       "Batch-3                                           0.860656                \n",
       "Batch-4                                           0.868852                \n",
       "Batch-5                                           0.868852                \n",
       "Average                                           0.851904                \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=0.9, tresh=1e-100  \\\n",
       "Batch-1                                           0.935484               \n",
       "Batch-2                                           0.935484               \n",
       "Batch-3                                           0.933333               \n",
       "Batch-4                                           0.900000               \n",
       "Batch-5                                           0.600000               \n",
       "Average                                           0.860860               \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.01  \\\n",
       "Batch-1                                           0.834711              \n",
       "Batch-2                                           0.826446              \n",
       "Batch-3                                           0.860656              \n",
       "Batch-4                                           0.868852              \n",
       "Batch-5                                           0.868852              \n",
       "Average                                           0.851904              \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.01  \\\n",
       "Batch-1                                           0.935484             \n",
       "Batch-2                                           0.935484             \n",
       "Batch-3                                           0.933333             \n",
       "Batch-4                                           0.900000             \n",
       "Batch-5                                           0.600000             \n",
       "Average                                           0.860860             \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.001  \\\n",
       "Batch-1                                           0.834711               \n",
       "Batch-2                                           0.826446               \n",
       "Batch-3                                           0.860656               \n",
       "Batch-4                                           0.868852               \n",
       "Batch-5                                           0.868852               \n",
       "Average                                           0.851904               \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.001  \\\n",
       "Batch-1                                           0.935484              \n",
       "Batch-2                                           0.935484              \n",
       "Batch-3                                           0.933333              \n",
       "Batch-4                                           0.900000              \n",
       "Batch-5                                           0.600000              \n",
       "Average                                           0.860860              \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.0001  \\\n",
       "Batch-1                                           0.834711                \n",
       "Batch-2                                           0.826446                \n",
       "Batch-3                                           0.860656                \n",
       "Batch-4                                           0.868852                \n",
       "Batch-5                                           0.868852                \n",
       "Average                                           0.851904                \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=0.0001  \\\n",
       "Batch-1                                           0.935484               \n",
       "Batch-2                                           0.935484               \n",
       "Batch-3                                           0.933333               \n",
       "Batch-4                                           0.900000               \n",
       "Batch-5                                           0.600000               \n",
       "Average                                           0.860860               \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=1e-100  \\\n",
       "Batch-1                                           0.834711                \n",
       "Batch-2                                           0.826446                \n",
       "Batch-3                                           0.860656                \n",
       "Batch-4                                           0.868852                \n",
       "Batch-5                                           0.868852                \n",
       "Average                                           0.851904                \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, tresh=1e-100  \n",
       "Batch-1                                           0.935484              \n",
       "Batch-2                                           0.935484              \n",
       "Batch-3                                           0.933333              \n",
       "Batch-4                                           0.900000              \n",
       "Batch-5                                           0.600000              \n",
       "Average                                           0.860860              \n",
       "\n",
       "[6 rows x 576 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}, tresh={param_combinations[i][-1]}'] = train_history[i] \n",
    "    eval_history[f'Test Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}, tresh={param_combinations[i][-1]}'] = test_history[i]\n",
    "    , tresh={}\n",
    "history_ig_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_ig_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_ig_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_ig_tfidf.loc['Average', test_col].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01  \\\n",
       "Batch-1                                           0.834711              \n",
       "Batch-2                                           0.826446              \n",
       "Batch-3                                           0.860656              \n",
       "Batch-4                                           0.868852              \n",
       "Batch-5                                           0.868852              \n",
       "Average                                           0.851904              \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01  \n",
       "Batch-1                                           0.935484            \n",
       "Batch-2                                           0.935484            \n",
       "Batch-3                                           0.933333            \n",
       "Batch-4                                           0.900000            \n",
       "Batch-5                                           0.600000            \n",
       "Average                                           0.860860            "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_ig_tfidf[['Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01', 'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=0.01']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.851904</td>\n",
       "      <td>0.860860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100  \\\n",
       "Batch-1                                           0.834711                \n",
       "Batch-2                                           0.826446                \n",
       "Batch-3                                           0.860656                \n",
       "Batch-4                                           0.868852                \n",
       "Batch-5                                           0.868852                \n",
       "Average                                           0.851904                \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100  \n",
       "Batch-1                                           0.935484              \n",
       "Batch-2                                           0.935484              \n",
       "Batch-3                                           0.933333              \n",
       "Batch-4                                           0.900000              \n",
       "Batch-5                                           0.600000              \n",
       "Average                                           0.860860              "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_ig_tfidf[['Train Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100', 'Test Acc (ngram=(1, 1)), min_df=0.3, max_df=0.5, tresh=1e-100']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get same score for using and without using information gain that is:\n",
    "<h3>86.01%</h3>\n",
    "\n",
    "> Recommend to <b>not use</b> INFORMATION GAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes +  Chi Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "confidence_interval_list = [0.0, .1, .2, .3, .4, .5, .6, .7, .8, .9, .95]\n",
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    chi2_val, p_val = chi2(train_count_features, train_labels)\n",
    "    chi2_res = list(zip(vectorizer.get_feature_names(), chi2_val, p_val))\n",
    "    \n",
    "    for confidence_interval in confidence_interval_list:\n",
    "        # if p-value > alpha, then accept H0 (independent)\n",
    "        alpha = 1.0 - confidence_interval\n",
    "        below_tresh = [word[0] for word in chi2_res if word[2] > alpha]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "\n",
    "        # train and evaluate\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "\n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(confidence_interval_list)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (confidence interval=0.0)</th>\n",
       "      <th>Test Acc (confidence interval=0.0)</th>\n",
       "      <th>Train Acc (confidence interval=0.1)</th>\n",
       "      <th>Test Acc (confidence interval=0.1)</th>\n",
       "      <th>Train Acc (confidence interval=0.2)</th>\n",
       "      <th>Test Acc (confidence interval=0.2)</th>\n",
       "      <th>Train Acc (confidence interval=0.3)</th>\n",
       "      <th>Test Acc (confidence interval=0.3)</th>\n",
       "      <th>Train Acc (confidence interval=0.4)</th>\n",
       "      <th>Test Acc (confidence interval=0.4)</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (confidence interval=0.6)</th>\n",
       "      <th>Test Acc (confidence interval=0.6)</th>\n",
       "      <th>Train Acc (confidence interval=0.7)</th>\n",
       "      <th>Test Acc (confidence interval=0.7)</th>\n",
       "      <th>Train Acc (confidence interval=0.8)</th>\n",
       "      <th>Test Acc (confidence interval=0.8)</th>\n",
       "      <th>Train Acc (confidence interval=0.9)</th>\n",
       "      <th>Test Acc (confidence interval=0.9)</th>\n",
       "      <th>Train Acc (confidence interval=0.95)</th>\n",
       "      <th>Test Acc (confidence interval=0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.976995</td>\n",
       "      <td>0.710108</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975329</td>\n",
       "      <td>0.735914</td>\n",
       "      <td>0.965479</td>\n",
       "      <td>0.723441</td>\n",
       "      <td>0.965438</td>\n",
       "      <td>0.696559</td>\n",
       "      <td>0.955575</td>\n",
       "      <td>0.742796</td>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.755699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (confidence interval=0.0)  \\\n",
       "Batch-1                             0.991736   \n",
       "Batch-2                             0.975207   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.975410   \n",
       "Batch-5                             0.959016   \n",
       "Average                             0.975356   \n",
       "\n",
       "         Test Acc (confidence interval=0.0)  \\\n",
       "Batch-1                            0.709677   \n",
       "Batch-2                            0.774194   \n",
       "Batch-3                            0.700000   \n",
       "Batch-4                            0.733333   \n",
       "Batch-5                            0.533333   \n",
       "Average                            0.690108   \n",
       "\n",
       "         Train Acc (confidence interval=0.1)  \\\n",
       "Batch-1                             0.991736   \n",
       "Batch-2                             0.975207   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.983607   \n",
       "Batch-5                             0.959016   \n",
       "Average                             0.976995   \n",
       "\n",
       "         Test Acc (confidence interval=0.1)  \\\n",
       "Batch-1                            0.709677   \n",
       "Batch-2                            0.774194   \n",
       "Batch-3                            0.733333   \n",
       "Batch-4                            0.800000   \n",
       "Batch-5                            0.533333   \n",
       "Average                            0.710108   \n",
       "\n",
       "         Train Acc (confidence interval=0.2)  \\\n",
       "Batch-1                             1.000000   \n",
       "Batch-2                             0.975207   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.983607   \n",
       "Batch-5                             0.975410   \n",
       "Average                             0.981927   \n",
       "\n",
       "         Test Acc (confidence interval=0.2)  \\\n",
       "Batch-1                            0.709677   \n",
       "Batch-2                            0.774194   \n",
       "Batch-3                            0.700000   \n",
       "Batch-4                            0.766667   \n",
       "Batch-5                            0.500000   \n",
       "Average                            0.690108   \n",
       "\n",
       "         Train Acc (confidence interval=0.3)  \\\n",
       "Batch-1                             1.000000   \n",
       "Batch-2                             0.975207   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.983607   \n",
       "Batch-5                             0.975410   \n",
       "Average                             0.981927   \n",
       "\n",
       "         Test Acc (confidence interval=0.3)  \\\n",
       "Batch-1                            0.709677   \n",
       "Batch-2                            0.774194   \n",
       "Batch-3                            0.733333   \n",
       "Batch-4                            0.766667   \n",
       "Batch-5                            0.500000   \n",
       "Average                            0.696774   \n",
       "\n",
       "         Train Acc (confidence interval=0.4)  \\\n",
       "Batch-1                             1.000000   \n",
       "Batch-2                             0.975207   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.983607   \n",
       "Batch-5                             0.975410   \n",
       "Average                             0.981927   \n",
       "\n",
       "         Test Acc (confidence interval=0.4)  ...  \\\n",
       "Batch-1                            0.709677  ...   \n",
       "Batch-2                            0.806452  ...   \n",
       "Batch-3                            0.733333  ...   \n",
       "Batch-4                            0.766667  ...   \n",
       "Batch-5                            0.500000  ...   \n",
       "Average                            0.703226  ...   \n",
       "\n",
       "         Train Acc (confidence interval=0.6)  \\\n",
       "Batch-1                             0.991736   \n",
       "Batch-2                             0.958678   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.975410   \n",
       "Batch-5                             0.975410   \n",
       "Average                             0.975329   \n",
       "\n",
       "         Test Acc (confidence interval=0.6)  \\\n",
       "Batch-1                            0.741935   \n",
       "Batch-2                            0.870968   \n",
       "Batch-3                            0.766667   \n",
       "Batch-4                            0.733333   \n",
       "Batch-5                            0.566667   \n",
       "Average                            0.735914   \n",
       "\n",
       "         Train Acc (confidence interval=0.7)  \\\n",
       "Batch-1                             0.983471   \n",
       "Batch-2                             0.958678   \n",
       "Batch-3                             0.967213   \n",
       "Batch-4                             0.950820   \n",
       "Batch-5                             0.967213   \n",
       "Average                             0.965479   \n",
       "\n",
       "         Test Acc (confidence interval=0.7)  \\\n",
       "Batch-1                            0.677419   \n",
       "Batch-2                            0.806452   \n",
       "Batch-3                            0.766667   \n",
       "Batch-4                            0.800000   \n",
       "Batch-5                            0.566667   \n",
       "Average                            0.723441   \n",
       "\n",
       "         Train Acc (confidence interval=0.8)  \\\n",
       "Batch-1                             0.975207   \n",
       "Batch-2                             0.942149   \n",
       "Batch-3                             0.975410   \n",
       "Batch-4                             0.959016   \n",
       "Batch-5                             0.975410   \n",
       "Average                             0.965438   \n",
       "\n",
       "         Test Acc (confidence interval=0.8)  \\\n",
       "Batch-1                            0.677419   \n",
       "Batch-2                            0.838710   \n",
       "Batch-3                            0.766667   \n",
       "Batch-4                            0.733333   \n",
       "Batch-5                            0.466667   \n",
       "Average                            0.696559   \n",
       "\n",
       "         Train Acc (confidence interval=0.9)  \\\n",
       "Batch-1                             0.958678   \n",
       "Batch-2                             0.942149   \n",
       "Batch-3                             0.959016   \n",
       "Batch-4                             0.950820   \n",
       "Batch-5                             0.967213   \n",
       "Average                             0.955575   \n",
       "\n",
       "         Test Acc (confidence interval=0.9)  \\\n",
       "Batch-1                            0.741935   \n",
       "Batch-2                            0.838710   \n",
       "Batch-3                            0.800000   \n",
       "Batch-4                            0.733333   \n",
       "Batch-5                            0.600000   \n",
       "Average                            0.742796   \n",
       "\n",
       "         Train Acc (confidence interval=0.95)  \\\n",
       "Batch-1                              0.942149   \n",
       "Batch-2                              0.950413   \n",
       "Batch-3                              0.959016   \n",
       "Batch-4                              0.942623   \n",
       "Batch-5                              0.950820   \n",
       "Average                              0.949004   \n",
       "\n",
       "         Test Acc (confidence interval=0.95)  \n",
       "Batch-1                             0.677419  \n",
       "Batch-2                             0.967742  \n",
       "Batch-3                             0.833333  \n",
       "Batch-4                             0.766667  \n",
       "Batch-5                             0.533333  \n",
       "Average                             0.755699  \n",
       "\n",
       "[6 rows x 22 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (confidence interval={confidence_interval_list[i]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (confidence interval={confidence_interval_list[i]})'] = test_history[i]\n",
    "    , tresh={}\n",
    "history_chi2 = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (confidence interval=0.95)'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_chi2.columns if col.startswith('Test')]\n",
    "test_col[history_chi2.loc['Average', test_col].argmax()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 1.0)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_col = [col for col in history_chi2.columns if col.startswith('Train')]\n",
    "plt.plot(confidence_interval_list, history_chi2.loc['Average', train_col], label='Train accuracy')\n",
    "plt.plot(confidence_interval_list, history_chi2.loc['Average', test_col], label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Confidence interval (%)')\n",
    "plt.xticks(confidence_interval_list)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.ylim([.5, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (confidence interval=0.95)</th>\n",
       "      <th>Test Acc (confidence interval=0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.942623</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.949004</td>\n",
       "      <td>0.755699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (confidence interval=0.95)  \\\n",
       "Batch-1                              0.942149   \n",
       "Batch-2                              0.950413   \n",
       "Batch-3                              0.959016   \n",
       "Batch-4                              0.942623   \n",
       "Batch-5                              0.950820   \n",
       "Average                              0.949004   \n",
       "\n",
       "         Test Acc (confidence interval=0.95)  \n",
       "Batch-1                             0.677419  \n",
       "Batch-2                             0.967742  \n",
       "Batch-3                             0.833333  \n",
       "Batch-4                             0.766667  \n",
       "Batch-5                             0.533333  \n",
       "Average                             0.755699  "
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_chi2[['Train Acc (confidence interval=0.95)', 'Test Acc (confidence interval=0.95)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer from above result we can get the best result with <b>confidence interval 95%</b>, that is:\n",
    "\n",
    "<h3>75.56%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes +  Chi Square + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 0.0, 0.7, 0.0), ((1, 1), 0.0, 0.7, 0.6), ((1, 1), 0.0, 0.7, 0.7)]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram = [(1, 1), (1, 2), (1, 3)]\n",
    "min_df = [0.0, .1, .2, .3]\n",
    "max_df = [.7 , .8, .9, 1.0]\n",
    "confidence_interval_list = [0.0, .6, .7, .8, .9, .95]\n",
    "\n",
    "param_combinations = list(product(ngram, min_df, max_df, confidence_interval_list))\n",
    "param_combinations[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    train_count_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_count_features = vectorizer.transform(features[test_idx])\n",
    "\n",
    "    chi2_val, p_val = chi2(train_count_features, train_labels)\n",
    "    chi2_res = list(zip(vectorizer.get_feature_names(), chi2_val, p_val))\n",
    "    \n",
    "    for param in param_combinations:\n",
    "        # if p-value > alpha, then accept H0 (independent)\n",
    "        alpha = 1.0 - param[-1]\n",
    "        below_tresh = [word[0] for word in chi2_res if word[2] > alpha]\n",
    "        new_features = remove_token(below_tresh, features)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(ngram_range=param[0], min_df=param[1], max_df=param[2])\n",
    "        train_features = tfidf_vectorizer.fit_transform(new_features[train_idx])\n",
    "        test_features = tfidf_vectorizer.transform(new_features[test_idx])\n",
    "\n",
    "        # train and evaluate\n",
    "        clf = MultinomialNB()\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "        \n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(param_combinations)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "# append the average accuracy\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.0)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.0)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.6)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.6)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.7)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.7)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.8)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.8)</th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.9)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.9)</th>\n",
       "      <th>...</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.6)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.6)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.7)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.7)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.8)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.8)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.9)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.9)</th>\n",
       "      <th>Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.95)</th>\n",
       "      <th>Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.991736</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.983471</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.958678</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.959016</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.690108</td>\n",
       "      <td>0.975329</td>\n",
       "      <td>0.735914</td>\n",
       "      <td>0.965479</td>\n",
       "      <td>0.723441</td>\n",
       "      <td>0.965438</td>\n",
       "      <td>0.696559</td>\n",
       "      <td>0.955575</td>\n",
       "      <td>0.742796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848598</td>\n",
       "      <td>0.861075</td>\n",
       "      <td>0.861713</td>\n",
       "      <td>0.861075</td>\n",
       "      <td>0.861713</td>\n",
       "      <td>0.861075</td>\n",
       "      <td>0.864991</td>\n",
       "      <td>0.861075</td>\n",
       "      <td>0.714090</td>\n",
       "      <td>0.768172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.0)  \\\n",
       "Batch-1                                           0.991736                            \n",
       "Batch-2                                           0.975207                            \n",
       "Batch-3                                           0.975410                            \n",
       "Batch-4                                           0.975410                            \n",
       "Batch-5                                           0.959016                            \n",
       "Average                                           0.975356                            \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.0)  \\\n",
       "Batch-1                                           0.709677                           \n",
       "Batch-2                                           0.774194                           \n",
       "Batch-3                                           0.700000                           \n",
       "Batch-4                                           0.733333                           \n",
       "Batch-5                                           0.533333                           \n",
       "Average                                           0.690108                           \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.6)  \\\n",
       "Batch-1                                           0.991736                            \n",
       "Batch-2                                           0.958678                            \n",
       "Batch-3                                           0.975410                            \n",
       "Batch-4                                           0.975410                            \n",
       "Batch-5                                           0.975410                            \n",
       "Average                                           0.975329                            \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.6)  \\\n",
       "Batch-1                                           0.741935                           \n",
       "Batch-2                                           0.870968                           \n",
       "Batch-3                                           0.766667                           \n",
       "Batch-4                                           0.733333                           \n",
       "Batch-5                                           0.566667                           \n",
       "Average                                           0.735914                           \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.7)  \\\n",
       "Batch-1                                           0.983471                            \n",
       "Batch-2                                           0.958678                            \n",
       "Batch-3                                           0.967213                            \n",
       "Batch-4                                           0.950820                            \n",
       "Batch-5                                           0.967213                            \n",
       "Average                                           0.965479                            \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.7)  \\\n",
       "Batch-1                                           0.677419                           \n",
       "Batch-2                                           0.806452                           \n",
       "Batch-3                                           0.766667                           \n",
       "Batch-4                                           0.800000                           \n",
       "Batch-5                                           0.566667                           \n",
       "Average                                           0.723441                           \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.8)  \\\n",
       "Batch-1                                           0.975207                            \n",
       "Batch-2                                           0.942149                            \n",
       "Batch-3                                           0.975410                            \n",
       "Batch-4                                           0.959016                            \n",
       "Batch-5                                           0.975410                            \n",
       "Average                                           0.965438                            \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.8)  \\\n",
       "Batch-1                                           0.677419                           \n",
       "Batch-2                                           0.838710                           \n",
       "Batch-3                                           0.766667                           \n",
       "Batch-4                                           0.733333                           \n",
       "Batch-5                                           0.466667                           \n",
       "Average                                           0.696559                           \n",
       "\n",
       "         Train Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.9)  \\\n",
       "Batch-1                                           0.958678                            \n",
       "Batch-2                                           0.942149                            \n",
       "Batch-3                                           0.959016                            \n",
       "Batch-4                                           0.950820                            \n",
       "Batch-5                                           0.967213                            \n",
       "Average                                           0.955575                            \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.0, max_df=0.7, confidence interval=0.9)  \\\n",
       "Batch-1                                           0.741935                           \n",
       "Batch-2                                           0.838710                           \n",
       "Batch-3                                           0.800000                           \n",
       "Batch-4                                           0.733333                           \n",
       "Batch-5                                           0.600000                           \n",
       "Average                                           0.742796                           \n",
       "\n",
       "         ...  \\\n",
       "Batch-1  ...   \n",
       "Batch-2  ...   \n",
       "Batch-3  ...   \n",
       "Batch-4  ...   \n",
       "Batch-5  ...   \n",
       "Average  ...   \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.6)  \\\n",
       "Batch-1                                           0.818182                            \n",
       "Batch-2                                           0.826446                            \n",
       "Batch-3                                           0.860656                            \n",
       "Batch-4                                           0.868852                            \n",
       "Batch-5                                           0.868852                            \n",
       "Average                                           0.848598                            \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.6)  \\\n",
       "Batch-1                                           0.935484                           \n",
       "Batch-2                                           0.903226                           \n",
       "Batch-3                                           0.933333                           \n",
       "Batch-4                                           0.933333                           \n",
       "Batch-5                                           0.600000                           \n",
       "Average                                           0.861075                           \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.7)  \\\n",
       "Batch-1                                           0.818182                            \n",
       "Batch-2                                           0.826446                            \n",
       "Batch-3                                           0.860656                            \n",
       "Batch-4                                           0.868852                            \n",
       "Batch-5                                           0.934426                            \n",
       "Average                                           0.861713                            \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.7)  \\\n",
       "Batch-1                                           0.935484                           \n",
       "Batch-2                                           0.903226                           \n",
       "Batch-3                                           0.933333                           \n",
       "Batch-4                                           0.933333                           \n",
       "Batch-5                                           0.600000                           \n",
       "Average                                           0.861075                           \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.8)  \\\n",
       "Batch-1                                           0.818182                            \n",
       "Batch-2                                           0.826446                            \n",
       "Batch-3                                           0.860656                            \n",
       "Batch-4                                           0.868852                            \n",
       "Batch-5                                           0.934426                            \n",
       "Average                                           0.861713                            \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.8)  \\\n",
       "Batch-1                                           0.935484                           \n",
       "Batch-2                                           0.903226                           \n",
       "Batch-3                                           0.933333                           \n",
       "Batch-4                                           0.933333                           \n",
       "Batch-5                                           0.600000                           \n",
       "Average                                           0.861075                           \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.9)  \\\n",
       "Batch-1                                           0.818182                            \n",
       "Batch-2                                           0.826446                            \n",
       "Batch-3                                           0.877049                            \n",
       "Batch-4                                           0.868852                            \n",
       "Batch-5                                           0.934426                            \n",
       "Average                                           0.864991                            \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.9)  \\\n",
       "Batch-1                                           0.935484                           \n",
       "Batch-2                                           0.903226                           \n",
       "Batch-3                                           0.933333                           \n",
       "Batch-4                                           0.933333                           \n",
       "Batch-5                                           0.600000                           \n",
       "Average                                           0.861075                           \n",
       "\n",
       "         Train Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.95)  \\\n",
       "Batch-1                                           0.793388                             \n",
       "Batch-2                                           0.801653                             \n",
       "Batch-3                                           0.877049                             \n",
       "Batch-4                                           0.549180                             \n",
       "Batch-5                                           0.549180                             \n",
       "Average                                           0.714090                             \n",
       "\n",
       "         Test Acc (ngram=(1, 3)), min_df=0.3, max_df=1.0, confidence interval=0.95)  \n",
       "Batch-1                                           0.903226                           \n",
       "Batch-2                                           0.870968                           \n",
       "Batch-3                                           0.933333                           \n",
       "Batch-4                                           0.566667                           \n",
       "Batch-5                                           0.566667                           \n",
       "Average                                           0.768172                           \n",
       "\n",
       "[6 rows x 576 columns]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}, confidence interval={param_combinations[i][-1]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (ngram={param_combinations[i][0]}), min_df={param_combinations[i][1]}, max_df={param_combinations[i][2]}, confidence interval={param_combinations[i][-1]})'] = test_history[i]\n",
    "    , tresh={}\n",
    "history_chi2_tfidf = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                                  'Batch-4', 'Batch-5', 'Average'])\n",
    "history_chi2_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)'"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_col = [col for col in history_chi2_tfidf.columns if col.startswith('Test')]\n",
    "test_col[history_chi2_tfidf.loc['Average', test_col].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)</th>\n",
       "      <th>Test Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.879813</td>\n",
       "      <td>0.873978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)  \\\n",
       "Batch-1                                           0.859504                             \n",
       "Batch-2                                           0.826446                             \n",
       "Batch-3                                           0.885246                             \n",
       "Batch-4                                           0.877049                             \n",
       "Batch-5                                           0.950820                             \n",
       "Average                                           0.879813                             \n",
       "\n",
       "         Test Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)  \n",
       "Batch-1                                           0.935484                           \n",
       "Batch-2                                           0.967742                           \n",
       "Batch-3                                           0.900000                           \n",
       "Batch-4                                           0.933333                           \n",
       "Batch-5                                           0.633333                           \n",
       "Average                                           0.873978                           "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_chi2_tfidf[['Train Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)', 'Test Acc (ngram=(1, 1)), min_df=0.2, max_df=0.7, confidence interval=0.95)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got <b>the best result</b> from Multinomial Naive Bayes Model with \n",
    "<b>chi-square</b> as feature selection with <b>confidence interval = 95%</b>,\n",
    "and another parameter from TF-IDF such as <b>minimum</b> of word's occurrences is <b>20%</b> of total documents, \n",
    "<b>maximum</b> of word's occurrences is <b>70%</b> of total documents, \n",
    "<b>only use 1 gram</b> that is: <h3>87.40%</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
