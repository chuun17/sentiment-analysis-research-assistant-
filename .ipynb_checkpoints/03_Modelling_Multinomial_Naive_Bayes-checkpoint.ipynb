{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('dataset/Data 1.xlsx', names=['comment', 'polarity'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min bnyk yg kecewa lo dgn update terbaru alih ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user id password mesti ke bank ya gpplah yg pe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saat transfer kadang ada muncul keterangan kon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>begitu saya update dan no tlpn saya statusnya ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tolong tambahkan fitur fingerprint atau face r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  polarity\n",
       "0  min bnyk yg kecewa lo dgn update terbaru alih ...         1\n",
       "1  user id password mesti ke bank ya gpplah yg pe...         1\n",
       "2  saat transfer kadang ada muncul keterangan kon...         1\n",
       "3  begitu saya update dan no tlpn saya statusnya ...         1\n",
       "4  tolong tambahkan fitur fingerprint atau face r...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "<ol>\n",
    "    <li>Case folding <b>(done at previous notebook)</b></li>\n",
    "    <li>Cleansing <b>(done at previous notebook)</b></li>\n",
    "    <li>Formalization</li>\n",
    "    <li>Stemming</li>\n",
    "    <li>Stopword Removal</li>\n",
    "    <li>Tokenizing</li>\n",
    "</ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalization (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 token pairs\n"
     ]
    }
   ],
   "source": [
    "formal_dict = {}\n",
    "with open('resources/formalization_dict.txt', 'r') as file:\n",
    "    i = 1\n",
    "    for row in file:\n",
    "        old, new = row.split('\\t')\n",
    "        i += 1\n",
    "        formal_dict[old] = new.lower().strip()\n",
    "\n",
    "print(f'There are {len(formal_dict)} token pairs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "formal_comment = []\n",
    "\n",
    "for comment in df.comment:\n",
    "    sentence = ' '+comment+' '\n",
    "    for false_word, true_word in formal_dict.items():\n",
    "        word = ' '+false_word+' '\n",
    "        sentence = sentence.replace(word, ' '+true_word+' ')\n",
    "    formal_comment.append(sentence)\n",
    "    \n",
    "print(f'We have {len(formal_comment)} comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming (Sastrawi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk yang kecewa lo dengan update baru alih alih sempurna malah susah nasabah mandiri masuk saya agar kurang tindak tipu jahat waktu ada transaksi yang lebih rb rp maka bisa di tambah security upa kirim nomor verifikasi yang kirim ke nomor hp sms banking trus harus di masuk dalam applikasi mandiri online agar benar bahwa si nasabah sedang laku transaksi dengan demikian pasti tetap aman mohon perhati ya min terimakasih'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = StemmerFactory().create_stemmer()\n",
    "comment_stemmed = [stemmer.stem(formal_comment[i]) for i in range(df.shape[0])]\n",
    "\n",
    "comment_stemmed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' min bnyk yang kecewa lo dengan update terbaru alih alih penyempurnaan malah menyusahkan nasabah mandiri masukan saya agar mengurangi tindak penipuan kejahatan sewaktu ada transaksi yang lebih rb rp maka bisa di tambahkan security berupa pengiriman nomor verifikasi yang dikirimkan ke nomor hp sms banking trus harus di masukkan dalam applikasi mandiri online agar benar bahwa si nasabah sedang melakukan transaksi dengan demikian pasti tetap aman mohon diperhatikan ya min terimakasih '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23 stopword list\n"
     ]
    }
   ],
   "source": [
    "stopwords = [\n",
    "    'yang', 'untuk', 'pada', 'antara', 'dan' , 'di', 'dari', 'hal', \n",
    "    'dalam', 'atau', 'kah', 'pun', 'dsb', 'dst', 'dll', 'toh', 'ya',\n",
    "    'saya', 'dengan', 'nya', 'ke', 'si', 'dah'\n",
    "]\n",
    "\n",
    "print(f'There are {len(stopwords)} stopword list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 152 comments\n"
     ]
    }
   ],
   "source": [
    "clean_comment = []\n",
    "for comment in comment_stemmed:\n",
    "    for token in stopwords:\n",
    "        word = ' '+token+' '\n",
    "        comment = comment.replace(word, ' ')\n",
    "    if sentence.strip():\n",
    "        clean_comment.append(comment.strip())\n",
    "        \n",
    "print(f'We have {len(clean_comment)} comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'min bnyk kecewa lo update baru alih alih sempurna malah susah nasabah mandiri masuk agar kurang tindak tipu jahat waktu ada transaksi lebih rb rp maka bisa tambah security upa kirim nomor verifikasi kirim nomor hp sms banking trus harus masuk applikasi mandiri online agar benar bahwa nasabah sedang laku transaksi demikian pasti tetap aman mohon perhati min terimakasih'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['min', 'bnyk', 'kecewa', 'lo', 'update', 'baru', 'alih', 'alih',\n",
       "       'sempurna', 'malah', 'susah', 'nasabah', 'mandiri', 'masuk',\n",
       "       'agar', 'kurang', 'tindak', 'tipu', 'jahat', 'waktu', 'ada',\n",
       "       'transaksi', 'lebih', 'rb', 'rp', 'maka', 'bisa', 'tambah',\n",
       "       'security', 'upa', 'kirim', 'nomor', 'verifikasi', 'kirim',\n",
       "       'nomor', 'hp', 'sms', 'banking', 'trus', 'harus', 'masuk',\n",
       "       'applikasi', 'mandiri', 'online', 'agar', 'benar', 'bahwa',\n",
       "       'nasabah', 'sedang', 'laku', 'transaksi', 'demikian', 'pasti',\n",
       "       'tetap', 'aman', 'mohon', 'perhati', 'min', 'terimakasih'],\n",
       "      dtype='<U11'),\n",
       "       array(['user', 'id', 'password', 'mesti', 'bank', 'gpplah', 'penting',\n",
       "       'aman', 'transaksi'], dtype='<U9')], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([np.array(comment.split()) for comment in clean_comment])\n",
    "features[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.552632\n",
       "1    0.447368\n",
       "Name: polarity, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(df.polarity)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0    0.694215\n",
      "1    0.305785\n",
      "Name: polarity, dtype: float64\n",
      "Test 1    1.0\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 0    0.628099\n",
      "1    0.371901\n",
      "Name: polarity, dtype: float64\n",
      "Test 1    0.741935\n",
      "0    0.258065\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 1    0.557377\n",
      "0    0.442623\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    1.0\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 0    0.508197\n",
      "1    0.491803\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    0.733333\n",
      "1    0.266667\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "Train 1    0.508197\n",
      "0    0.491803\n",
      "Name: polarity, dtype: float64\n",
      "Test 0    0.8\n",
      "1    0.2\n",
      "Name: polarity, dtype: float64\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=0)\n",
    "for train, test in kfold.split(features, labels):\n",
    "    print('Train', df.iloc[train, 1].value_counts() / len(train))\n",
    "    print('Test', df.iloc[test, 1].value_counts() / len(test))\n",
    "    print('===================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1\n",
      " 0    0.553719\n",
      "1    0.446281\n",
      "Name: polarity, dtype: float64\n",
      "test 1\n",
      " 0    0.548387\n",
      "1    0.451613\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 2\n",
      " 0    0.553719\n",
      "1    0.446281\n",
      "Name: polarity, dtype: float64\n",
      "test 2\n",
      " 0    0.548387\n",
      "1    0.451613\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 3\n",
      " 0    0.557377\n",
      "1    0.442623\n",
      "Name: polarity, dtype: float64\n",
      "test 3\n",
      " 0    0.533333\n",
      "1    0.466667\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 4\n",
      " 0    0.54918\n",
      "1    0.45082\n",
      "Name: polarity, dtype: float64\n",
      "test 4\n",
      " 0    0.566667\n",
      "1    0.433333\n",
      "Name: polarity, dtype: float64\n",
      "===================\n",
      "train 5\n",
      " 0    0.54918\n",
      "1    0.45082\n",
      "Name: polarity, dtype: float64\n",
      "test 5\n",
      " 0    0.566667\n",
      "1    0.433333\n",
      "Name: polarity, dtype: float64\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "# split and save index of each batch train-test\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "\n",
    "i = 1\n",
    "for train, test in skf.split(df.comment, df.polarity):\n",
    "    np.save(f'dataset/train_{i}', train)\n",
    "    np.save(f'dataset/test_{i}', test)\n",
    "    print(f'train {i}\\n', df.iloc[train, 1].value_counts()/len(train))\n",
    "    print(f'test {i}\\n', df.iloc[test, 1].value_counts()/len(test))\n",
    "    print('===================')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and evaluate model completed\n"
     ]
    }
   ],
   "source": [
    "NUM_BATCHES = 5\n",
    "features = np.array(clean_comment)\n",
    "labels = np.array(df.polarity)\n",
    "smoothing_parameter = [1.0, .1, .01, .001]\n",
    "train_eval, test_eval = [], []\n",
    "\n",
    "for i in range(NUM_BATCHES):\n",
    "\n",
    "    train_idx = np.load(f'dataset/train_{i+1}.npy')\n",
    "    test_idx = np.load(f'dataset/test_{i+1}.npy')\n",
    "    vectorizer = CountVectorizer()\n",
    "    \n",
    "    # \n",
    "    train_features = vectorizer.fit_transform(features[train_idx])\n",
    "    test_features = vectorizer.transform(features[test_idx])\n",
    "    train_labels = labels[train_idx]\n",
    "    test_labels = labels[test_idx]\n",
    "    \n",
    "    for param in smoothing_parameter:\n",
    "        clf = MultinomialNB(alpha=param)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        train_acc = clf.score(train_features, train_labels)\n",
    "        test_acc = clf.score(test_features, test_labels)\n",
    "        \n",
    "        train_eval.append(train_acc)\n",
    "        test_eval.append(test_acc)\n",
    "\n",
    "print('Train and evaluate model completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "NUM_PARAMS = len(smoothing_parameter)\n",
    "train_history = [[] for i in range(NUM_PARAMS)]\n",
    "test_history = [[] for i in range(NUM_PARAMS)]\n",
    "\n",
    "for i in range(len(train_eval)):\n",
    "    idx = i % NUM_PARAMS\n",
    "    train_history[idx].append(train_eval[i])\n",
    "    test_history[idx].append(test_eval[i])\n",
    "\n",
    "for i in range(NUM_PARAMS):\n",
    "    train_history[i].append(sum(train_history[i])/NUM_BATCHES)\n",
    "    test_history[i].append(sum(test_history[i])/NUM_BATCHES)\n",
    "\n",
    "if len(train_history[-1]) == NUM_BATCHES+1:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Acc (a=1.0)</th>\n",
       "      <th>Test Acc (a=1.0)</th>\n",
       "      <th>Train Acc (a=0.1)</th>\n",
       "      <th>Test Acc (a=0.1)</th>\n",
       "      <th>Train Acc (a=0.01)</th>\n",
       "      <th>Test Acc (a=0.01)</th>\n",
       "      <th>Train Acc (a=0.001)</th>\n",
       "      <th>Test Acc (a=0.001)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Batch-1</th>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-2</th>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.975207</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-3</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-4</th>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Batch-5</th>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.968731</td>\n",
       "      <td>0.722366</td>\n",
       "      <td>0.985205</td>\n",
       "      <td>0.676989</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.637849</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.618065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train Acc (a=1.0)  Test Acc (a=1.0)  Train Acc (a=0.1)  \\\n",
       "Batch-1           0.975207          0.741935           1.000000   \n",
       "Batch-2           0.950413          0.903226           0.975207   \n",
       "Batch-3           0.975410          0.800000           0.975410   \n",
       "Batch-4           0.967213          0.766667           0.983607   \n",
       "Batch-5           0.975410          0.400000           0.991803   \n",
       "Average           0.968731          0.722366           0.985205   \n",
       "\n",
       "         Test Acc (a=0.1)  Train Acc (a=0.01)  Test Acc (a=0.01)  \\\n",
       "Batch-1          0.677419            1.000000           0.709677   \n",
       "Batch-2          0.774194            0.975207           0.612903   \n",
       "Batch-3          0.766667            0.983607           0.733333   \n",
       "Batch-4          0.833333            0.991803           0.833333   \n",
       "Batch-5          0.333333            0.991803           0.300000   \n",
       "Average          0.676989            0.988484           0.637849   \n",
       "\n",
       "         Train Acc (a=0.001)  Test Acc (a=0.001)  \n",
       "Batch-1             1.000000            0.677419  \n",
       "Batch-2             0.975207            0.612903  \n",
       "Batch-3             0.983607            0.700000  \n",
       "Batch-4             0.991803            0.800000  \n",
       "Batch-5             0.991803            0.300000  \n",
       "Average             0.988484            0.618065  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_history = {}\n",
    "for i in range(NUM_PARAMS):\n",
    "    eval_history[f'Train Acc (a={smoothing_parameter[i]})'] = train_history[i] \n",
    "    eval_history[f'Test Acc (a={smoothing_parameter[i]})'] = test_history[i]\n",
    "    \n",
    "history = pd.DataFrame(eval_history, index=['Batch-1', 'Batch-2', 'Batch-3', \n",
    "                                            'Batch-4', 'Batch-5', 'Average'])\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the lower the alpha value, the lower the accuracy value on the test data (Overfitting)\n",
    "\n",
    "We got <b>the best result</b> from Multinomial Naive Bayes Model with <b>alpha = 1.0</b> that is: <h3>72.24%</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
